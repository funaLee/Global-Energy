{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Model Specific Preprocessing\n",
    "\n",
    "**Goals:**\n",
    "- **Linear Regression**: One-Hot Encoding, Outlier Removal (IQR), VIF check, Standard Scaling. *Fixed: Excludes One-Hot features from scaling/outliers. Log-Tx skewed features.*\n",
    "- **SVR**: Robust Scaling (outlier sensitive), One-Hot Encoding. *Fixed: Excludes One-Hot features from scaling.*\n",
    "- **XGBoost**: Ordinal Encoding (tree-friendly).\n",
    "- Export specific datasets: `lr_final_prep.csv`, `svr_final_prep.csv`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T16:35:59.890158Z",
     "iopub.status.busy": "2025-12-29T16:35:59.889965Z",
     "iopub.status.idle": "2025-12-29T16:36:02.270905Z",
     "shell.execute_reply": "2025-12-29T16:36:02.269847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from ../data/processed/common_preprocessed.csv: (3473, 25)\n",
      "--- Processing Linear Regression Data ---\n",
      "Log-transformed Financial flows to developing countries (US $)\n",
      "Log-transformed Renewables (% equivalent primary energy)\n",
      "Whitelisted Entities (protected from outlier removal): ['China', 'United States', 'India', 'Russian Federation', 'Japan', 'Germany', 'Brazil', 'Canada']\n",
      "Protected Rows: 140, Rows to Clean: 3333\n",
      "Skipping outlier removal for 3 columns with IQR=0 (likely imputed): ['Renewables (% equivalent primary energy)', 'Electricity from nuclear (TWh)', 'Financial flows to developing countries (US $)']\n",
      "Removed 1241 outlier rows (threshold=3.0).\n",
      "Final LR Data Shape after Whitelist Protection: (2232, 198)\n",
      "Running VIF Removal...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped features due to VIF > 10: ['Primary energy consumption per capita (kWh/person)_lag1', 'Electricity from fossil fuels (TWh)', 'gdp_per_capita_lag1', 'Year', 'Access to electricity (% of population)', 'Access to clean fuels for cooking']\n",
      "Running Standard Scaling...\n",
      "Saved LR data: (2232, 192)\n",
      "\n",
      "--- Processing SVR Data ---\n",
      "Loaded data from ../data/processed/common_preprocessed.csv: (3473, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVR data: (3473, 198)\n",
      "\n",
      "--- Processing XGBoost Data ---\n",
      "Loaded data from ../data/processed/common_preprocessed.csv: (3473, 25)\n",
      "Saved XGBoost data: (3473, 25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler, OrdinalEncoder, StandardScaler\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath(os.path.join('../src')))\n",
    "from preprocessing import load_data, encode_features, remove_outliers, remove_high_vif\n",
    "\n",
    "# Load Common Data\n",
    "df = load_data('../data/processed/common_preprocessed.csv')\n",
    "\n",
    "# --- 1. Linear Regression ---\n",
    "print(\"--- Processing Linear Regression Data ---\")\n",
    "target = 'Value_co2_emissions_kt_by_country'\n",
    "\n",
    "# 1.0 Log Transformation for highly skewed/imputed features\n",
    "skewed_cols = ['Financial flows to developing countries (US $)', 'Renewables (% equivalent primary energy)']\n",
    "for col in skewed_cols:\n",
    "    if col in df.columns:\n",
    "        # Use log1p to handle zeros\n",
    "        df[col] = np.log1p(df[col])\n",
    "        print(f\"Log-transformed {col}\")\n",
    "\n",
    "df_lr = encode_features(df, method='onehot')\n",
    "\n",
    "# 1.1 Outliers Removal (IQR) - WITH WHITELIST PROTECTION\n",
    "# Goals: Remove statistical outliers but KEEP critical economies (USA, China, etc.)\n",
    "# which are outliers by definition but vital for the model.\n",
    "\n",
    "# List of Major Economies to Protect (Global Top Emitters/GDP)\n",
    "WHITELIST = ['China', 'United States', 'India', 'Russian Federation', 'Japan', 'Germany', 'Brazil', 'Canada']\n",
    "print(f\"Whitelisted Entities (protected from outlier removal): {WHITELIST}\")\n",
    "\n",
    "# Strategy:\n",
    "# 1. Split df into Whitelisted vs Non-Whitelisted\n",
    "# 2. Apply Outlier Removal ONLY to Non-Whitelisted rows\n",
    "# 3. Concatenate back together\n",
    "\n",
    "# Identify index of whitelisted rows\n",
    "whitelist_mask = pd.Series(False, index=df_lr.index)\n",
    "for country in WHITELIST:\n",
    "    col_name = f'Entity_{country}'\n",
    "    if col_name in df_lr.columns:\n",
    "        whitelist_mask = whitelist_mask | (df_lr[col_name] == 1)\n",
    "\n",
    "df_protected = df_lr[whitelist_mask].copy()\n",
    "df_to_clean = df_lr[~whitelist_mask].copy()\n",
    "\n",
    "print(f\"Protected Rows: {len(df_protected)}, Rows to Clean: {len(df_to_clean)}\")\n",
    "\n",
    "# Remove outliers from the 'To Clean' subset using original threshold\n",
    "# Note: remove_outliers function in src/preprocessing.py handles the basic logic\n",
    "df_cleaned_subset = remove_outliers(df_to_clean, method='iqr', threshold=3.0)\n",
    "\n",
    "# Merge back and sort\n",
    "df_lr = pd.concat([df_protected, df_cleaned_subset], axis=0).sort_index()\n",
    "print(f\"Final LR Data Shape after Whitelist Protection: {df_lr.shape}\")\n",
    "\n",
    "# 1.2 VIF Removal (Multicollinearity)\n",
    "print(\"Running VIF Removal...\")\n",
    "df_lr = remove_high_vif(df_lr, target, threshold=10, exclude_cols=['Financial flows to developing countries (US $)'])\n",
    "\n",
    "# 1.3 Standard Scaling\n",
    "print(\"Running Standard Scaling...\")\n",
    "scaler_lr = StandardScaler()\n",
    "numeric_cols_lr = df_lr.select_dtypes(include=['float64', 'int64']).columns\n",
    "feature_cols_lr = [c for c in numeric_cols_lr if c != target and not c.startswith('Entity_')]\n",
    "\n",
    "df_lr[feature_cols_lr] = scaler_lr.fit_transform(df_lr[feature_cols_lr])\n",
    "\n",
    "df_lr.to_csv('../data/processed/lr_final_prep.csv', index=False)\n",
    "print(f\"Saved LR data: {df_lr.shape}\")\n",
    "\n",
    "# --- 2. SVR ---\n",
    "print(\"\\n--- Processing SVR Data ---\")\n",
    "# Reload original to avoid double log-tx (or we can apply log-tx here too? SVR typically benefits from it)\n",
    "df_svr_base = load_data('../data/processed/common_preprocessed.csv')\n",
    "# Let's apply Log-Tx here as well for consistency, SVR sensitive to scale\n",
    "for col in skewed_cols:\n",
    "    if col in df_svr_base.columns:\n",
    "        df_svr_base[col] = np.log1p(df_svr_base[col])\n",
    "\n",
    "df_svr = encode_features(df_svr_base, method='onehot')\n",
    "numeric_cols = df_svr.select_dtypes(include=['float64', 'int64']).columns\n",
    "# Robust Scaling: Exclude target and One-Hot columns\n",
    "svr_feats = [c for c in numeric_cols if c != target and not c.startswith('Entity_')]\n",
    "scaler = RobustScaler()\n",
    "df_svr[svr_feats] = scaler.fit_transform(df_svr[svr_feats])\n",
    "df_svr.to_csv('../data/processed/svr_final_prep.csv', index=False)\n",
    "print(f\"Saved SVR data: {df_svr.shape}\")\n",
    "\n",
    "# --- 3. XGBoost ---\n",
    "print(\"\\n--- Processing XGBoost Data ---\")\n",
    "# Tree models handle outliers and collinearity well. We load ORIGINAL (no log-tx needed, but helpful)\n",
    "df_xgb_base = load_data('../data/processed/common_preprocessed.csv')\n",
    "df_xgb = encode_features(df_xgb_base, method='ordinal')\n",
    "df_xgb.to_csv('../data/processed/xgb_final_prep.csv', index=False)\n",
    "print(f\"Saved XGBoost data: {df_xgb.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
