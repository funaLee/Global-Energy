{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Phase 1 - Du bao chuoi thoi gian (Forecasting)\n",
    "\n",
    "**Muc tieu:**\n",
    "- Danh gia mo hinh voi Time-Series Split (Train < 2015, Test >= 2015)\n",
    "- So sanh voi Phase 0.5 (Random Split) de kiem tra Data Leakage\n",
    "- Mo phong thuc te: Huan luyen tren qua khu, du bao tuong lai\n",
    "\n",
    "**Ket qua mong doi:**\n",
    "- Bang so sanh 6 thi nghiem (3 models x 2 approaches)\n",
    "- So sanh R2 giua Phase 0.5 va Phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Thiet lap moi truong va tai du lieu"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1.1 Import thu vien\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Them src vao path\n",
    "sys.path.append(os.path.abspath(os.path.join('../src')))\n",
    "from evaluation import evaluate_model, compare_models\n",
    "from preprocessing import load_data\n",
    "\n",
    "# Cau hinh\n",
    "pd.set_option('display.max_columns', 30)\n",
    "RANDOM_STATE = 42\n",
    "TARGET = 'Value_co2_emissions_kt_by_country'\n",
    "SPLIT_YEAR = 2015  # Train < 2015, Test >= 2015\n",
    "\n",
    "print('Thu vien da duoc import thanh cong.')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1.2 Tai du lieu da tien xu ly cho tung model\n",
    "df_lr = load_data('../data/processed/lr_final_prep.csv')\n",
    "df_svr = load_data('../data/processed/svr_final_prep.csv')\n",
    "df_xgb = load_data('../data/processed/xgb_final_prep.csv')\n",
    "\n",
    "# Kiem tra cot Year trong du lieu\n",
    "print(f'LR co cot Year: {\"Year\" in df_lr.columns}')\n",
    "print(f'SVR co cot Year: {\"Year\" in df_svr.columns}')\n",
    "print(f'XGB co cot Year: {\"Year\" in df_xgb.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1.3 Tai du lieu common de lay thong tin Year (LR va SVR da bi loai Year)\n",
    "df_common = load_data('../data/processed/common_preprocessed.csv')\n",
    "\n",
    "# Tao index mapping Year cho LR va SVR\n",
    "# LR data co it dong hon do loai outliers, can align theo index\n",
    "print(f'\\nPhan bo Year trong du lieu:')\n",
    "print(f'  Common: {df_common[\"Year\"].min()} - {df_common[\"Year\"].max()}')\n",
    "print(f'  XGB: {df_xgb[\"Year\"].min()} - {df_xgb[\"Year\"].max()}')\n",
    "print(f'\\nSo luong mau theo nam (XGB):')\n",
    "print(df_xgb.groupby('Year').size().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1.4 Dinh nghia cac ham tach features (giong Phase 0.5)\n",
    "\n",
    "def get_pooled_features(df, target, has_entity_onehot=True):\n",
    "    \"\"\"\n",
    "    Pooled Data: Loai bo lag features va Entity encoding.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    lag_cols = [c for c in df_copy.columns if 'lag' in c.lower()]\n",
    "    \n",
    "    if has_entity_onehot:\n",
    "        entity_cols = [c for c in df_copy.columns if c.startswith('Entity_')]\n",
    "    else:\n",
    "        entity_cols = ['Entity'] if 'Entity' in df_copy.columns else []\n",
    "    \n",
    "    year_cols = ['Year'] if 'Year' in df_copy.columns else []\n",
    "    drop_cols = lag_cols + entity_cols + year_cols + [target]\n",
    "    drop_cols = [c for c in drop_cols if c in df_copy.columns]\n",
    "    \n",
    "    X = df_copy.drop(columns=drop_cols)\n",
    "    y = df_copy[target]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def get_panel_features(df, target, has_entity_onehot=True):\n",
    "    \"\"\"\n",
    "    Panel Data: Giu lai lag features va Entity encoding.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    year_cols = ['Year'] if 'Year' in df_copy.columns else []\n",
    "    drop_cols = year_cols + [target]\n",
    "    drop_cols = [c for c in drop_cols if c in df_copy.columns]\n",
    "    \n",
    "    X = df_copy.drop(columns=drop_cols)\n",
    "    y = df_copy[target]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "print('Cac ham tach features da duoc dinh nghia.')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1.5 Dinh nghia ham chia du lieu theo thoi gian\n",
    "\n",
    "def time_series_split(df, df_year_source, split_year, target):\n",
    "    \"\"\"\n",
    "    Chia du lieu theo moc thoi gian.\n",
    "    Train: Year < split_year\n",
    "    Test: Year >= split_year\n",
    "    \n",
    "    df: DataFrame chinh (co the khong co cot Year)\n",
    "    df_year_source: DataFrame co cot Year de tham chieu\n",
    "    \"\"\"\n",
    "    # Neu df co cot Year, dung truc tiep\n",
    "    if 'Year' in df.columns:\n",
    "        train_mask = df['Year'] < split_year\n",
    "        test_mask = df['Year'] >= split_year\n",
    "    else:\n",
    "        # Neu khong co Year, dung index tu df_year_source\n",
    "        # Dam bao index khop\n",
    "        common_idx = df.index.intersection(df_year_source.index)\n",
    "        year_series = df_year_source.loc[common_idx, 'Year']\n",
    "        train_mask = year_series < split_year\n",
    "        test_mask = year_series >= split_year\n",
    "        # Chi lay cac index co trong ca 2\n",
    "        df = df.loc[common_idx]\n",
    "    \n",
    "    df_train = df[train_mask]\n",
    "    df_test = df[test_mask]\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "print(f'Se chia du lieu: Train < {SPLIT_YEAR}, Test >= {SPLIT_YEAR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pooled Data Approach\n",
    "\n",
    "**Dac diem:** Coi moi quan sat la doc lap, khong su dung thong tin ve quoc gia va lich su."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2.1 Linear Regression - Pooled\n",
    "print('=== 2.1 LINEAR REGRESSION - POOLED ===')\n",
    "\n",
    "# Chia theo thoi gian (dung XGB data vi co Year)\n",
    "df_train_xgb, df_test_xgb = time_series_split(df_xgb, df_xgb, SPLIT_YEAR, TARGET)\n",
    "\n",
    "# Lay index tuong ung cho LR data\n",
    "train_idx = df_train_xgb.index.intersection(df_lr.index)\n",
    "test_idx = df_test_xgb.index.intersection(df_lr.index)\n",
    "\n",
    "df_lr_train = df_lr.loc[train_idx]\n",
    "df_lr_test = df_lr.loc[test_idx]\n",
    "\n",
    "X_train, y_train = get_pooled_features(df_lr_train, TARGET, has_entity_onehot=True)\n",
    "X_test, y_test = get_pooled_features(df_lr_test, TARGET, has_entity_onehot=True)\n",
    "\n",
    "print(f'Train size: {X_train.shape[0]} (Year < {SPLIT_YEAR})')\n",
    "print(f'Test size: {X_test.shape[0]} (Year >= {SPLIT_YEAR})')\n",
    "print(f'So luong features: {X_train.shape[1]}')\n",
    "\n",
    "model_lr_pooled = Ridge(alpha=1.0, random_state=RANDOM_STATE)\n",
    "model_lr_pooled.fit(X_train, y_train)\n",
    "y_pred = model_lr_pooled.predict(X_test)\n",
    "\n",
    "result_lr_pooled = evaluate_model(y_test, y_pred, 'Linear Regression - Pooled')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2.2 SVR - Pooled\n",
    "print('=== 2.2 SVR - POOLED ===')\n",
    "\n",
    "# Lay index tuong ung cho SVR data\n",
    "train_idx = df_train_xgb.index.intersection(df_svr.index)\n",
    "test_idx = df_test_xgb.index.intersection(df_svr.index)\n",
    "\n",
    "df_svr_train = df_svr.loc[train_idx]\n",
    "df_svr_test = df_svr.loc[test_idx]\n",
    "\n",
    "X_train, y_train = get_pooled_features(df_svr_train, TARGET, has_entity_onehot=True)\n",
    "X_test, y_test = get_pooled_features(df_svr_test, TARGET, has_entity_onehot=True)\n",
    "\n",
    "print(f'Train size: {X_train.shape[0]}')\n",
    "print(f'Test size: {X_test.shape[0]}')\n",
    "print(f'So luong features: {X_train.shape[1]}')\n",
    "\n",
    "# SVR voi target scaling (giong Phase 0.5)\n",
    "model_svr_pooled = TransformedTargetRegressor(\n",
    "    regressor=SVR(kernel='rbf', C=10, epsilon=0.1),\n",
    "    transformer=StandardScaler()\n",
    ")\n",
    "model_svr_pooled.fit(X_train, y_train)\n",
    "y_pred = model_svr_pooled.predict(X_test)\n",
    "\n",
    "result_svr_pooled = evaluate_model(y_test, y_pred, 'SVR - Pooled')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2.3 XGBoost - Pooled\n",
    "print('=== 2.3 XGBOOST - POOLED ===')\n",
    "\n",
    "X_train, y_train = get_pooled_features(df_train_xgb, TARGET, has_entity_onehot=False)\n",
    "X_test, y_test = get_pooled_features(df_test_xgb, TARGET, has_entity_onehot=False)\n",
    "\n",
    "print(f'Train size: {X_train.shape[0]}')\n",
    "print(f'Test size: {X_test.shape[0]}')\n",
    "print(f'So luong features: {X_train.shape[1]}')\n",
    "\n",
    "model_xgb_pooled = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model_xgb_pooled.fit(X_train, y_train, verbose=False)\n",
    "y_pred = model_xgb_pooled.predict(X_test)\n",
    "\n",
    "result_xgb_pooled = evaluate_model(y_test, y_pred, 'XGBoost - Pooled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Panel Data Approach\n",
    "\n",
    "**Dac diem:** Su dung Fixed Effects (Entity encoding) va Lag Features de hoc xu huong lich su."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3.1 Linear Regression - Panel\n",
    "print('=== 3.1 LINEAR REGRESSION - PANEL ===')\n",
    "\n",
    "X_train, y_train = get_panel_features(df_lr_train, TARGET, has_entity_onehot=True)\n",
    "X_test, y_test = get_panel_features(df_lr_test, TARGET, has_entity_onehot=True)\n",
    "\n",
    "print(f'Train size: {X_train.shape[0]}')\n",
    "print(f'Test size: {X_test.shape[0]}')\n",
    "print(f'So luong features: {X_train.shape[1]} (bao gom Entity One-Hot va Lag)')\n",
    "\n",
    "model_lr_panel = Ridge(alpha=1.0, random_state=RANDOM_STATE)\n",
    "model_lr_panel.fit(X_train, y_train)\n",
    "y_pred = model_lr_panel.predict(X_test)\n",
    "\n",
    "result_lr_panel = evaluate_model(y_test, y_pred, 'Linear Regression - Panel')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3.2 SVR - Panel\n",
    "print('=== 3.2 SVR - PANEL ===')\n",
    "\n",
    "X_train, y_train = get_panel_features(df_svr_train, TARGET, has_entity_onehot=True)\n",
    "X_test, y_test = get_panel_features(df_svr_test, TARGET, has_entity_onehot=True)\n",
    "\n",
    "print(f'Train size: {X_train.shape[0]}')\n",
    "print(f'Test size: {X_test.shape[0]}')\n",
    "print(f'So luong features: {X_train.shape[1]} (bao gom Entity One-Hot va Lag)')\n",
    "\n",
    "model_svr_panel = TransformedTargetRegressor(\n",
    "    regressor=SVR(kernel='rbf', C=10, epsilon=0.1),\n",
    "    transformer=StandardScaler()\n",
    ")\n",
    "model_svr_panel.fit(X_train, y_train)\n",
    "y_pred = model_svr_panel.predict(X_test)\n",
    "\n",
    "result_svr_panel = evaluate_model(y_test, y_pred, 'SVR - Panel')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3.3 XGBoost - Panel\n",
    "print('=== 3.3 XGBOOST - PANEL ===')\n",
    "\n",
    "X_train, y_train = get_panel_features(df_train_xgb, TARGET, has_entity_onehot=False)\n",
    "X_test, y_test = get_panel_features(df_test_xgb, TARGET, has_entity_onehot=False)\n",
    "\n",
    "print(f'Train size: {X_train.shape[0]}')\n",
    "print(f'Test size: {X_test.shape[0]}')\n",
    "print(f'So luong features: {X_train.shape[1]} (bao gom Entity Ordinal va Lag)')\n",
    "\n",
    "model_xgb_panel = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model_xgb_panel.fit(X_train, y_train, verbose=False)\n",
    "y_pred = model_xgb_panel.predict(X_test)\n",
    "\n",
    "result_xgb_panel = evaluate_model(y_test, y_pred, 'XGBoost - Panel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tong hop va so sanh ket qua"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4.1 Tao bang so sanh tong hop Phase 1\n",
    "all_results = [\n",
    "    result_lr_pooled,\n",
    "    result_svr_pooled,\n",
    "    result_xgb_pooled,\n",
    "    result_lr_panel,\n",
    "    result_svr_panel,\n",
    "    result_xgb_panel\n",
    "]\n",
    "\n",
    "df_results_p1 = compare_models(all_results)\n",
    "df_results_p1['Approach'] = ['Pooled', 'Pooled', 'Pooled', 'Panel', 'Panel', 'Panel']\n",
    "df_results_p1['Algorithm'] = ['Linear Regression', 'SVR', 'XGBoost'] * 2\n",
    "df_results_p1 = df_results_p1[['Algorithm', 'Approach', 'RMSE', 'MAE', 'R2']]\n",
    "\n",
    "print('\\n=== BANG TONG HOP KET QUA PHASE 1 (TIME-SERIES SPLIT) ===')\n",
    "print(df_results_p1.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4.2 So sanh voi Phase 0.5\n",
    "print('\\n=== SO SANH PHASE 0.5 vs PHASE 1 ===')\n",
    "\n",
    "# Load ket qua Phase 0.5\n",
    "df_results_p05 = pd.read_csv('../data/results/phase05_results.csv')\n",
    "\n",
    "# Tao bang so sanh R2\n",
    "comparison = pd.DataFrame({\n",
    "    'Algorithm': ['Linear Regression', 'SVR', 'XGBoost'] * 2,\n",
    "    'Approach': ['Pooled', 'Pooled', 'Pooled', 'Panel', 'Panel', 'Panel'],\n",
    "    'R2_Phase05': df_results_p05['R2'].values,\n",
    "    'R2_Phase1': df_results_p1['R2'].values\n",
    "})\n",
    "comparison['R2_Change'] = comparison['R2_Phase1'] - comparison['R2_Phase05']\n",
    "comparison['Change_%'] = (comparison['R2_Change'] / comparison['R2_Phase05'] * 100).round(2)\n",
    "\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4.3 Truc quan hoa so sanh Phase 0.5 vs Phase 1\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Chart 1: R2 comparison\n",
    "ax1 = axes[0]\n",
    "x = np.arange(6)\n",
    "width = 0.35\n",
    "labels = [f'{a}\\n{b}' for a, b in zip(comparison['Algorithm'], comparison['Approach'])]\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, comparison['R2_Phase05'], width, label='Phase 0.5 (Random)', color='#3498db')\n",
    "bars2 = ax1.bar(x + width/2, comparison['R2_Phase1'], width, label='Phase 1 (Time)', color='#e74c3c')\n",
    "\n",
    "ax1.set_ylabel('R2 Score')\n",
    "ax1.set_title('So sanh R2: Random Split vs Time-Series Split')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(labels, fontsize=8)\n",
    "ax1.legend()\n",
    "ax1.axhline(y=0.8, color='green', linestyle='--', alpha=0.5, label='Nguong tot (0.8)')\n",
    "\n",
    "# Chart 2: R2 change percentage\n",
    "ax2 = axes[1]\n",
    "colors = ['#27ae60' if x >= 0 else '#c0392b' for x in comparison['Change_%']]\n",
    "bars = ax2.bar(x, comparison['Change_%'], color=colors)\n",
    "ax2.set_ylabel('Thay doi R2 (%)')\n",
    "ax2.set_title('Muc do thay doi R2 tu Phase 0.5 sang Phase 1')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(labels, fontsize=8)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "for bar, val in zip(bars, comparison['Change_%']):\n",
    "    ax2.annotate(f'{val:.1f}%', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                xytext=(0, 3), textcoords='offset points', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4.4 Nhan xet va ket luan\n",
    "print('\\n=== NHAN XET KET QUA PHASE 1 ===')\n",
    "\n",
    "# Tim model tot nhat\n",
    "best_idx = df_results_p1['R2'].idxmax()\n",
    "best_model = df_results_p1.loc[best_idx]\n",
    "\n",
    "print(f'\\n1. Model tot nhat (Phase 1): {best_model[\"Algorithm\"]} - {best_model[\"Approach\"]}')\n",
    "print(f'   R2 = {best_model[\"R2\"]:.4f}, RMSE = {best_model[\"RMSE\"]:.2f}')\n",
    "\n",
    "# Phan tich Data Leakage\n",
    "avg_r2_drop = comparison['R2_Change'].mean()\n",
    "print(f'\\n2. Phan tich Data Leakage:')\n",
    "print(f'   - Trung binh R2 giam: {avg_r2_drop:.4f} ({avg_r2_drop/comparison[\"R2_Phase05\"].mean()*100:.1f}%)')\n",
    "\n",
    "if avg_r2_drop < -0.1:\n",
    "    print('   => Co dau hieu Data Leakage o Phase 0.5 (R2 giam dang ke)')\n",
    "elif avg_r2_drop < 0:\n",
    "    print('   => R2 giam nhe, day la binh thuong khi du bao tuong lai')\n",
    "else:\n",
    "    print('   => Model on dinh, khong co Data Leakage')\n",
    "\n",
    "# So sanh Pooled vs Panel\n",
    "pooled_r2 = df_results_p1[df_results_p1['Approach'] == 'Pooled']['R2'].mean()\n",
    "panel_r2 = df_results_p1[df_results_p1['Approach'] == 'Panel']['R2'].mean()\n",
    "\n",
    "print(f'\\n3. So sanh Approach (Phase 1):')\n",
    "print(f'   - Pooled R2 trung binh: {pooled_r2:.4f}')\n",
    "print(f'   - Panel R2 trung binh: {panel_r2:.4f}')\n",
    "\n",
    "if panel_r2 > pooled_r2:\n",
    "    print('   => Panel Data van tot hon Pooled trong du bao thuc te')\n",
    "else:\n",
    "    print('   => Pooled Data cho ket qua tuong duong hoac tot hon')\n",
    "\n",
    "print('\\n4. Ket luan:')\n",
    "print('   - Phase 1 (Time-Series Split) phan anh kha nang du bao thuc te')\n",
    "print('   - Ket qua nay dang tin cay hon Phase 0.5 (Random Split)')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4.5 Luu ket qua\n",
    "import os\n",
    "os.makedirs('../data/results', exist_ok=True)\n",
    "\n",
    "# Luu ket qua Phase 1\n",
    "df_results_p1.to_csv('../data/results/phase1_results.csv', index=False)\n",
    "print('Da luu ket qua Phase 1 vao: ../data/results/phase1_results.csv')\n",
    "\n",
    "# Luu bang so sanh\n",
    "comparison.to_csv('../data/results/phase05_vs_phase1_comparison.csv', index=False)\n",
    "print('Da luu bang so sanh vao: ../data/results/phase05_vs_phase1_comparison.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}