{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Data Preprocessing Pipeline\n",
    "\n",
    "**Mục tiêu**: Thực hiện pipeline tiền xử lý cho 3 thuật toán: Linear Regression, SVR, XGBoost\n",
    "\n",
    "**Tương ứng Report Section 3**: Phương pháp & Pipeline Tiền xử lý\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Tải dữ liệu gốc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "df = pd.read_csv('../data/raw/global-data-on-sustainable-energy.csv')  \n",
    "print(f\"Raw data shape: {df.shape}\")\n",
    "\n",
    "# Convert all string numbers with commas to float\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object' and col not in ['Entity']:\n",
    "        try:\n",
    "            df[col] = df[col].str.replace(',', '').astype(float)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Common Preprocessing\n",
    "\n",
    "Các bước chung cho tất cả thuật toán:\n",
    "1. Xử lý Missing Values (Median Imputation)\n",
    "2. Tạo Lag Features\n",
    "3. Remove năm 2020 (COVID anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'Value_co2_emissions_kt_by_country'\n",
    "\n",
    "# Whitelist major economies (G20+ và các nước phát thải lớn)\n",
    "WHITELIST = [\n",
    "    'China', 'United States', 'India', 'Russia', 'Japan', 'Germany', \n",
    "    'South Korea', 'Iran', 'Saudi Arabia', 'Indonesia', 'Canada', \n",
    "    'Mexico', 'South Africa', 'Brazil', 'Australia', 'Turkey', \n",
    "    'United Kingdom', 'France', 'Ítaly', 'Poland', 'Taiwan', \n",
    "    'Thailand', 'Spain', 'Malaysia', 'Egypt', 'Vietnăm', 'Pakistan',\n",
    "    'Argentina', 'Venezuela', 'United Arab Emirates', 'Netherlands',\n",
    "    'Iraq', 'Philippines', 'Kazakhstan', 'Algeria', 'Kuwait', \n",
    "    'Belgium', 'Czechia', 'Morocco'\n",
    "]\n",
    "\n",
    "# 1. Median Imputation\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "print(f\"Missing values after imputation: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# 2. Lag Features\n",
    "lag_cols = [TARGET, 'gdp_per_capita', 'Primary energy consumption per capita (kWh/person)']\n",
    "for col in lag_cols:\n",
    "    if col in df.columns:\n",
    "        df[f'{col}_lag1'] = df.groupby('Entity')[col].shift(1)\n",
    "\n",
    "# Remove first year per country (no lag available)\n",
    "df = df.dropna(subset=[f'{TARGET}_lag1'])\n",
    "print(f\"Shape after lag creation: {df.shape}\")\n",
    "\n",
    "# Save common preprocessed data\n",
    "df.to_csv('../data/processed/common_preprocessed.csv', index=False)\n",
    "print(f\"Saved common_preprocessed.csv: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Linear Regression Preprocessing\n",
    "\n",
    "Đặc biệt cho LR:\n",
    "- **Log Transform** cho skewed features (giảm ảnh hưởng của extreme values)\n",
    "- **One-Hot Encoding** cho Entity (LR cần dummy variables)\n",
    "- **IQR Outlier Removal** với Whitelist major economies\n",
    "- **StandardScaler** (Z-Score Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = df.copy()\n",
    "\n",
    "# Remove 2020 (COVID anomaly)\n",
    "df_lr = df_lr[df_lr['Year'] != 2020]\n",
    "print(f\"After removing 2020: {df_lr.shape}\")\n",
    "\n",
    "# Log Transform cho skewed features\n",
    "skewed_cols = ['Financial flows to developing countries (US $)', \n",
    "               'Electricity from fossil fuels (TWh)',\n",
    "               'Electricity from nuclear (TWh)',\n",
    "               'Electricity from renewables (TWh)',\n",
    "               TARGET, f'{TARGET}_lag1']\n",
    "\n",
    "for col in skewed_cols:\n",
    "    if col in df_lr.columns:\n",
    "        # log1p để handle giá trị 0\n",
    "        df_lr[col] = np.log1p(df_lr[col].clip(lower=0))\n",
    "\n",
    "print(f\"Applied log transform to {len(skewed_cols)} columns\")\n",
    "\n",
    "# IQR Outlier Removal (excluding whitelist)\n",
    "Q1 = df_lr[TARGET].quantile(0.25)\n",
    "Q3 = df_lr[TARGET].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "outlier_mask = ((df_lr[TARGET] < lower) | (df_lr[TARGET] > upper))\n",
    "whitelist_mask = df_lr['Entity'].isin(WHITELIST)\n",
    "df_lr = df_lr[~outlier_mask | whitelist_mask]\n",
    "print(f\"After outlier removal: {df_lr.shape}\")\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_lr = pd.get_dummies(df_lr, columns=['Entity'], prefix='Entity')\n",
    "\n",
    "# StandardScaler (Z-Score) - exclude binary columns\n",
    "scale_cols = [c for c in df_lr.columns if c not in [TARGET, 'Year'] and not c.startswith('Entity_')]\n",
    "scaler_lr = StandardScaler()\n",
    "df_lr[scale_cols] = scaler_lr.fit_transform(df_lr[scale_cols])\n",
    "\n",
    "print(f\"LR final shape: {df_lr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 SVR Preprocessing\n",
    "\n",
    "Đặc biệt cho SVR:\n",
    "- **Log Transform** cho skewed features (giống LR)\n",
    "- **Ordinal Encoding** cho Entity (tiết kiệm memory, SVR không cần One-Hot)\n",
    "- **IQR Outlier Removal** với Whitelist (SVR rất nhạy cảm với outliers)\n",
    "- **RobustScaler** (tốt hơn StandardScaler vì dùng median/IQR thay vì mean/std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svr = df.copy()\n",
    "\n",
    "# Remove 2020 (COVID anomaly)\n",
    "df_svr = df_svr[df_svr['Year'] != 2020]\n",
    "print(f\"After removing 2020: {df_svr.shape}\")\n",
    "\n",
    "# Log Transform cho skewed features (giống LR)\n",
    "for col in skewed_cols:\n",
    "    if col in df_svr.columns:\n",
    "        df_svr[col] = np.log1p(df_svr[col].clip(lower=0))\n",
    "\n",
    "print(f\"Applied log transform to {len(skewed_cols)} columns\")\n",
    "\n",
    "# IQR Outlier Removal (excluding whitelist)\n",
    "Q1 = df_svr[TARGET].quantile(0.25)\n",
    "Q3 = df_svr[TARGET].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "outlier_mask = ((df_svr[TARGET] < lower) | (df_svr[TARGET] > upper))\n",
    "whitelist_mask = df_svr['Entity'].isin(WHITELIST)\n",
    "df_svr = df_svr[~outlier_mask | whitelist_mask]\n",
    "print(f\"After outlier removal: {df_svr.shape}\")\n",
    "\n",
    "# Ordinal Encoding (giống XGBoost)\n",
    "entity_map_svr = {e: i for i, e in enumerate(df_svr['Entity'].unique())}\n",
    "df_svr['Entity_Encoded'] = df_svr['Entity'].map(entity_map_svr)\n",
    "df_svr = df_svr.drop('Entity', axis=1)\n",
    "\n",
    "# RobustScaler (tốt hơn StandardScaler cho SVR)\n",
    "# RobustScaler dùng median và IQR, ít bị ảnh hưởng bởi outliers còn sót\n",
    "scale_cols_svr = [c for c in df_svr.columns if c not in [TARGET, 'Year', 'Entity_Encoded']]\n",
    "scaler_svr = RobustScaler()\n",
    "df_svr[scale_cols_svr] = scaler_svr.fit_transform(df_svr[scale_cols_svr])\n",
    "\n",
    "print(f\"SVR final shape: {df_svr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 XGBoost Preprocessing\n",
    "\n",
    "Đặc biệt cho XGBoost:\n",
    "- **Không cần Log Transform** (tree-based tự handle skewness)\n",
    "- **Ordinal Encoding** cho Entity\n",
    "- **Không loại bỏ outliers** (tree-based robust với outliers)\n",
    "- **Không cần scaling** (tree-based không phụ thuộc vào scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb = df.copy()\n",
    "\n",
    "# Ordinal Encoding\n",
    "entity_map_xgb = {e: i for i, e in enumerate(df_xgb['Entity'].unique())}\n",
    "df_xgb['Entity_Encoded'] = df_xgb['Entity'].map(entity_map_xgb)\n",
    "df_xgb = df_xgb.drop('Entity', axis=1)\n",
    "\n",
    "# Không cần scaling, không cần loại outliers\n",
    "print(f\"XGBoost final shape: {df_xgb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all 3 datasets\n",
    "df_lr.to_csv('../data/processed/lr_final_prep.csv', index=False)\n",
    "df_svr.to_csv('../data/processed/svr_final_prep.csv', index=False)\n",
    "df_xgb.to_csv('../data/processed/xgb_final_prep.csv', index=False)\n",
    "\n",
    "print(\"✅ Saved preprocessed data!\")\n",
    "print(f\"  - lr_final_prep.csv: {df_lr.shape}\")\n",
    "print(f\"  - svr_final_prep.csv: {df_svr.shape}\")\n",
    "print(f\"  - xgb_final_prep.csv: {df_xgb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Preprocessing Pipeline Comparison:**\n",
    "\n",
    "| Thuật toán | Log Transform | Encoding | Outlier Handling | Scaling |\n",
    "|---|---|---|---|---|\n",
    "| **Linear Regression** | ✅ Yes (skewed features) | One-Hot | IQR + Whitelist | StandardScaler |\n",
    "| **SVR** | ✅ Yes (skewed features) | Ordinal | IQR + Whitelist | RobustScaler |\n",
    "| **XGBoost** | ❌ No | Ordinal | None (keep all) | None |\n",
    "\n",
    "**Common Steps (tất cả thuật toán):**\n",
    "- Median Imputation cho missing values\n",
    "- Lag Features: CO2_lag1, GDP_lag1, Energy_lag1\n",
    "\n",
    "**Key Differences:**\n",
    "- **LR**: One-Hot Encoding → nhiều cột, StandardScaler (mean=0, std=1)\n",
    "- **SVR**: RobustScaler (dùng median/IQR) → ít nhạy cảm với outliers còn sót\n",
    "- **XGBoost**: Tree-based → không cần transform, tự handle non-linear patterns\n",
    "- **Outliers**: LR & SVR loại bỏ outliers nhưng giữ major economies (G20+)\n",
    "\n",
    "**Output Files:**\n",
    "- `common_preprocessed.csv`: Dữ liệu chung sau imputation + lag features\n",
    "- `lr_final_prep.csv`: Dữ liệu cho Linear Regression\n",
    "- `svr_final_prep.csv`: Dữ liệu cho SVR\n",
    "- `xgb_final_prep.csv`: Dữ liệu cho XGBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}