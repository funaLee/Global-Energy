{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02. Preprocessing Pipeline\n",
                "\n",
                "**Mục tiêu**: Thực hiện pipeline tiền xử lý cho 3 thuật toán: Linear Regression, SVR, XGBoost\n",
                "\n",
                "**Tương ứng Report Section 3**: Phương pháp & Pipeline Tiền xử lý\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
                "from sklearn.impute import SimpleImputer\n",
                "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import sys\n",
                "import os\n",
                "sys.path.append(os.path.abspath('../src'))\n",
                "\n",
                "print(\"Libraries loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.1 Load Raw Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load raw data\n",
                "df = pd.read_csv('../data/raw/Global_Data_filtered.csv')\n",
                "print(f\"Raw data shape: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.2 Common Preprocessing\n",
                "\n",
                "Các bước chung cho tất cả thuật toán:\n",
                "1. Xử lý Missing Values (Median Imputation)\n",
                "2. Tạo Lag Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "TARGET = 'Value_co2_emissions_kt_by_country'\n",
                "\n",
                "# 1. Median Imputation\n",
                "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
                "imputer = SimpleImputer(strategy='median')\n",
                "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
                "print(f\"Missing values after imputation: {df.isnull().sum().sum()}\")\n",
                "\n",
                "# 2. Lag Features\n",
                "lag_cols = [TARGET, 'gdp_per_capita', 'Primary energy consumption per capita (kWh/person)']\n",
                "for col in lag_cols:\n",
                "    if col in df.columns:\n",
                "        df[f'{col}_lag1'] = df.groupby('Entity')[col].shift(1)\n",
                "\n",
                "# Remove first year per country (no lag)\n",
                "df = df.dropna(subset=[f'{TARGET}_lag1'])\n",
                "print(f\"Shape after lag creation: {df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.3 Linear Regression Preprocessing\n",
                "\n",
                "Đặc biệt cho LR:\n",
                "- Log Transform cho skewed features\n",
                "- One-Hot Encoding cho Entity\n",
                "- IQR Outlier Removal (với Whitelist major economies)\n",
                "- VIF-based Feature Selection\n",
                "- Z-Score Scaling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_lr = df.copy()\n",
                "\n",
                "# Whitelist major economies (G20+)\n",
                "WHITELIST = [\n",
                "    'China', 'United States', 'India', 'Russia', 'Japan', 'Germany', \n",
                "    'South Korea', 'Iran', 'Saudi Arabia', 'Indonesia', 'Canada', \n",
                "    'Mexico', 'South Africa', 'Brazil', 'Australia', 'Turkey', \n",
                "    'United Kingdom', 'France', 'Italy', 'Poland', 'Taiwan', \n",
                "    'Thailand', 'Spain', 'Malaysia', 'Egypt', 'Vietnam', 'Pakistan',\n",
                "    'Argentina', 'Venezuela', 'United Arab Emirates', 'Netherlands',\n",
                "    'Iraq', 'Philippines', 'Kazakhstan', 'Algeria', 'Kuwait', \n",
                "    'Belgium', 'Czechia', 'Morocco'\n",
                "]\n",
                "\n",
                "# Remove 2020 (COVID anomaly)\n",
                "df_lr = df_lr[df_lr['Year'] != 2020]\n",
                "\n",
                "# IQR Outlier Removal (excluding whitelist)\n",
                "Q1 = df_lr[TARGET].quantile(0.25)\n",
                "Q3 = df_lr[TARGET].quantile(0.75)\n",
                "IQR = Q3 - Q1\n",
                "lower = Q1 - 1.5 * IQR\n",
                "upper = Q3 + 1.5 * IQR\n",
                "\n",
                "outlier_mask = ((df_lr[TARGET] < lower) | (df_lr[TARGET] > upper))\n",
                "whitelist_mask = df_lr['Entity'].isin(WHITELIST)\n",
                "df_lr = df_lr[~outlier_mask | whitelist_mask]\n",
                "\n",
                "print(f\"LR data after outlier removal: {df_lr.shape}\")\n",
                "\n",
                "# One-Hot Encoding\n",
                "df_lr = pd.get_dummies(df_lr, columns=['Entity'], prefix='Entity')\n",
                "\n",
                "# Z-Score Scaling (exclude binary columns)\n",
                "scale_cols = [c for c in df_lr.columns if c not in [TARGET, 'Year'] and not c.startswith('Entity_')]\n",
                "scaler = StandardScaler()\n",
                "df_lr[scale_cols] = scaler.fit_transform(df_lr[scale_cols])\n",
                "\n",
                "print(f\"LR final shape: {df_lr.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.4 XGBoost Preprocessing\n",
                "\n",
                "Đặc biệt cho XGBoost:\n",
                "- Không cần Log Transform\n",
                "- Ordinal Encoding cho Entity\n",
                "- Không loại bỏ outliers\n",
                "- Không cần scaling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_xgb = df.copy()\n",
                "\n",
                "# Ordinal Encoding\n",
                "entity_map = {e: i for i, e in enumerate(df_xgb['Entity'].unique())}\n",
                "df_xgb['Entity_Encoded'] = df_xgb['Entity'].map(entity_map)\n",
                "df_xgb = df_xgb.drop('Entity', axis=1)\n",
                "\n",
                "print(f\"XGBoost final shape: {df_xgb.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.5 Save Processed Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save\n",
                "df_lr.to_csv('../data/processed/lr_final_prep.csv', index=False)\n",
                "df_xgb.to_csv('../data/processed/xgb_final_prep.csv', index=False)\n",
                "\n",
                "print(\"✅ Saved preprocessed data!\")\n",
                "print(f\"  - lr_final_prep.csv: {df_lr.shape}\")\n",
                "print(f\"  - xgb_final_prep.csv: {df_xgb.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "| Thuật toán | Log Transform | Encoding | Outlier | Scaling |\n",
                "|---|---|---|---|---|\n",
                "| **Linear Regression** | ✅ Yes | One-Hot | IQR + Whitelist | Z-Score |\n",
                "| **XGBoost** | ❌ No | Ordinal | None | None |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}