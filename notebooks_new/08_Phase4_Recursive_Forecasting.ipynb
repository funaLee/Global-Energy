{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 08: Phase 4 - Dự báo đệ quy (Recursive Forecasting)\n",
                "\n",
                "**Mục tiêu:**\n",
                "- Thực hiện **Dự báo đệ quy (Recursive Forecasting)** từ 2015 đến 2019.\n",
                "- **Yêu cầu (User Request)**: \n",
                "    1. **Global Baseline**: Sử dụng `data/processed/lr_final_prep.csv` (Dữ liệu đã StandardScaled + OHE).\n",
                "    2. **Hybrid Model**: Sử dụng `data/processed/common_preprocessed.csv` (Dữ liệu gốc), thực hiện tiền xử lý và training **ON-THE-FLY** (giống Notebook 07).\n",
                "- **Cơ chế**: \n",
                "    - Duy trì 2 luồng dữ liệu song song trong vòng lặp đệ quy.\n",
                "    - **Global**: Update Lag đã Scaled.\n",
                "    - **Hybrid**: Update Lag Raw (hoặc theo quy trình của Hybrid).\n",
                "- **Đánh giá**: So sánh sai số tích lũy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import json\n",
                "import joblib\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.linear_model import Ridge\n",
                "from xgboost import XGBRegressor\n",
                "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
                "import os\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "plt.style.use('seaborn-v0_8')\n",
                "\n",
                "# Constants\n",
                "SPLIT_YEAR = 2015\n",
                "TEST_END_YEAR = 2019\n",
                "TARGET = 'Value_co2_emissions_kt_by_country'\n",
                "LAG_TARGET = f'{TARGET}_lag1'\n",
                "\n",
                "DATA_DIR = '../data/processed/'\n",
                "MODEL_DIR = '../models/'\n",
                "RESULTS_DIR = '../data/results/'\n",
                "\n",
                "os.makedirs(RESULTS_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Chuẩn bị Dữ liệu (Dual Data Streams)\n",
                "\n",
                "Chúng ta cần load 2 bộ dữ liệu riêng biệt:\n",
                "1. `df_lr`: Cho Linear Regression (đã Scaled).\n",
                "2. `df_common`: Cho Hybrid Model (Raw)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_dual_data():\n",
                "    # 1. LOAD GLOBAL DATA (LR Final Prep)\n",
                "    print(\"Loading Global Data (lr_final_prep.csv)...\")\n",
                "    df_lr = pd.read_csv(os.path.join(DATA_DIR, 'lr_final_prep.csv'))\n",
                "    if 'Year' in df_lr.columns:\n",
                "        df_lr['Year'] = pd.to_numeric(df_lr['Year'])\n",
                "        \n",
                "    # Recover Entity for mapping if missing (from OHE)\n",
                "    if 'Entity' not in df_lr.columns:\n",
                "        print(\"Recovering 'Entity' from OHE in df_lr...\")\n",
                "        entity_cols = [c for c in df_lr.columns if c.startswith('Entity_')]\n",
                "        df_lr['Entity'] = df_lr[entity_cols].idxmax(axis=1).apply(lambda x: x.replace('Entity_', ''))\n",
                "\n",
                "    # 2. LOAD HYBRID DATA (Common Preprocessed)\n",
                "    print(\"Loading Hybrid Data (common_preprocessed.csv)...\")\n",
                "    df_common = pd.read_csv(os.path.join(DATA_DIR, 'common_preprocessed.csv'))\n",
                "    if 'Year' in df_common.columns:\n",
                "        df_common['Year'] = pd.to_numeric(df_common['Year'])\n",
                "        \n",
                "    # Preprocessing for Hybrid (as per Notebook 07 LOGIC)\n",
                "    # Notebook 07 trained on lr_final_prep actually, but user wants us to use COMMON here.\n",
                "    # Common has incomplete features maybe? \n",
                "    # Let's generate OHE for Entity in Common because Hybrid Backbone (Ridge) needs it.\n",
                "    print(\"Preprocessing Grid for Hybrid (OHE)...\")\n",
                "    dummies = pd.get_dummies(df_common['Entity'], prefix='Entity', dtype=int)\n",
                "    df_hybrid = pd.concat([df_common, dummies], axis=1)\n",
                "    \n",
                "    # Hybrid in 07 used 'lr_final_prep' which was Scaled.\n",
                "    # If we use Common (Raw), we might need to Scale it to be comparable or strictly follow user.\n",
                "    # User said: \"hybrid thì dùng common (nói chung là trước đấy huấn luyện sao giờ huấn luyện lại y chang)\"\n",
                "    # If 07 used Scaled data, and we must use Common (Raw), then we SHOULD Scale Common.\n",
                "    # Let's Scale df_hybrid numeric features.\n",
                "    print(\"Scaling Hybrid Data (StandardScaler logic)...\")\n",
                "    # Exclude Entity, Year, Target, OHE columns (0/1)\n",
                "    non_scale_cols = [TARGET, 'Year', 'Entity'] + [c for c in df_hybrid.columns if c.startswith('Entity_')]\n",
                "    scale_cols = [c for c in df_hybrid.columns if c not in non_scale_cols]\n",
                "    \n",
                "    # Fit scaler on TRAIN ONLY (< 2015)\n",
                "    train_mask = df_hybrid['Year'] < SPLIT_YEAR\n",
                "    means = df_hybrid.loc[train_mask, scale_cols].mean()\n",
                "    stds = df_hybrid.loc[train_mask, scale_cols].std().replace(0, 1)\n",
                "    \n",
                "    for col in scale_cols:\n",
                "        df_hybrid[col] = (df_hybrid[col] - means[col]) / stds[col]\n",
                "        \n",
                "    # Store stats for recursive update later\n",
                "    hybrid_stats = {'means': means, 'stds': stds}\n",
                "    \n",
                "    return df_lr, df_hybrid, hybrid_stats\n",
                "\n",
                "df_lr, df_hybrid, hybrid_stats = load_dual_data()\n",
                "print(f\"Global Data (Scaled): {df_lr.shape}\")\n",
                "print(f\"Hybrid Data (Scaled form Common): {df_hybrid.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Train Models ON-THE-FLY\n",
                "\n",
                "Huấn luyện lại cả 2 mô hình trên tập Training (< 2015) của dữ liệu tương ứng."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Features\n",
                "drop_cols_lr = [TARGET, 'Year', 'Entity'] \n",
                "features_lr = [c for c in df_lr.columns if c not in drop_cols_lr]\n",
                "\n",
                "drop_cols_hybrid = [TARGET, 'Year', 'Entity']\n",
                "features_hybrid = [c for c in df_hybrid.columns if c not in drop_cols_hybrid]\n",
                "\n",
                "# SPLIT TRAIN (< 2015)\n",
                "mask_train_lr = df_lr['Year'] < SPLIT_YEAR\n",
                "X_train_lr = df_lr.loc[mask_train_lr, features_lr]\n",
                "y_train_lr = df_lr.loc[mask_train_lr, TARGET]\n",
                "\n",
                "mask_train_hb = df_hybrid['Year'] < SPLIT_YEAR\n",
                "X_train_hb = df_hybrid.loc[mask_train_hb, features_hybrid]\n",
                "y_train_hb = df_hybrid.loc[mask_train_hb, TARGET]\n",
                "\n",
                "# --- 1. Train Global Baseline (Ridge) ---\n",
                "print(\"Training Global Baseline (Ridge)...\")\n",
                "model_global = Ridge(alpha=10.0)\n",
                "model_global.fit(X_train_lr, y_train_lr)\n",
                "print(\"Global Baseline Trained.\")\n",
                "\n",
                "# --- 2. Train Hybrid (Ridge + XGB) ---\n",
                "print(\"Training Hybrid Model (Ridge + XGB)...\")\n",
                "# A. Backbone\n",
                "hybrid_ridge = Ridge(alpha=10.0)\n",
                "hybrid_ridge.fit(X_train_hb, y_train_hb)\n",
                "y_pred_backbone = hybrid_ridge.predict(X_train_hb)\n",
                "residuals_train = y_train_hb - y_pred_backbone\n",
                "\n",
                "# B. Residual Corrector (XGBoost)\n",
                "xgb_params = {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05, 'n_jobs': -1, 'random_state': 42}\n",
                "hybrid_xgb = XGBRegressor(**xgb_params)\n",
                "hybrid_xgb.fit(X_train_hb, residuals_train)\n",
                "print(\"Hybrid Model Trained.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Recursive Forecasting Loop (Dual Stream)\n",
                "\n",
                "Chúng ta xử lý từng năm:\n",
                "- Dự báo cho năm `t`.\n",
                "- Cập nhật Lag cho năm `t+1`.\n",
                "- **Lưu ý**: \n",
                "    - `df_lr` cần update Lag theo kiểu Scaled (Dùng Stats của df_lr).\n",
                "    - `df_hybrid` cần update Lag theo kiểu Scaled (Dùng Stats của df_common mà ta đã tính `hybrid_stats`).\n",
                "    - Target ở cả 2 dataframe đều là Raw Value (kt CO2), nên logic (Pred - Mean)/Std là giống nhau, chỉ khác giá trị Mean/Std của từng bộ dữ liệu."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Bắt đầu Dự báo Đệ quy (2015-2019)...\")\n",
                "\n",
                "# Calculate Target stats for Scaling Lag (Raw Target -> Scaled Lag)\n",
                "# NB: We need stats from the respective training sets\n",
                "target_mean_lr = y_train_lr.mean()\n",
                "target_std_lr = y_train_lr.std()\n",
                "\n",
                "target_mean_hb = y_train_hb.mean()\n",
                "target_std_hb = y_train_hb.std()\n",
                "\n",
                "# Prepare Test Copies\n",
                "df_test_lr = df_lr[df_lr['Year'] >= SPLIT_YEAR].copy()\n",
                "df_test_hb = df_hybrid[df_hybrid['Year'] >= SPLIT_YEAR].copy()\n",
                "\n",
                "predictions_global = []\n",
                "predictions_hybrid = []\n",
                "\n",
                "years_to_predict = sorted(df_test_lr['Year'].unique())\n",
                "\n",
                "for year in years_to_predict:\n",
                "    print(f\"\\n>>> Processing Year: {year}\")\n",
                "    \n",
                "    # --- A. GLOBAL (df_lr stream) ---\n",
                "    current_year_lr = df_test_lr[df_test_lr['Year'] == year]\n",
                "    X_curr_lr = current_year_lr[features_lr]\n",
                "    \n",
                "    y_pred_g = model_global.predict(X_curr_lr)\n",
                "    y_pred_g = np.maximum(y_pred_g, 0)\n",
                "    \n",
                "    res_g = current_year_lr[['Entity', 'Year', TARGET]].copy()\n",
                "    res_g['Pred_Global'] = y_pred_g\n",
                "    predictions_global.append(res_g)\n",
                "    \n",
                "    # Update Next Lag (Global)\n",
                "    next_year = year + 1\n",
                "    if next_year <= TEST_END_YEAR:\n",
                "        pred_map = dict(zip(current_year_lr['Entity'], y_pred_g))\n",
                "        # Scale: (Pred - Mean) / Std\n",
                "        pred_map_scaled = {k: (v - target_mean_lr) / target_std_lr for k, v in pred_map.items()}\n",
                "        \n",
                "        mask_next = df_test_lr['Year'] == next_year\n",
                "        next_ents = df_test_lr.loc[mask_next, 'Entity']\n",
                "        # Assuming lag col name is same\n",
                "        updated_lags = next_ents.map(pred_map_scaled).fillna(df_test_lr.loc[mask_next, LAG_TARGET])\n",
                "        df_test_lr.loc[mask_next, LAG_TARGET] = updated_lags\n",
                "\n",
                "    # --- B. HYBRID (df_hybrid stream) ---\n",
                "    current_year_hb = df_test_hb[df_test_hb['Year'] == year]\n",
                "    X_curr_hb = current_year_hb[features_hybrid]\n",
                "    \n",
                "    pred_ridge = hybrid_ridge.predict(X_curr_hb)\n",
                "    pred_xgb = hybrid_xgb.predict(X_curr_hb)\n",
                "    y_pred_h = pred_ridge + pred_xgb\n",
                "    y_pred_h = np.maximum(y_pred_h, 0)\n",
                "    \n",
                "    res_h = current_year_hb[['Entity', 'Year', TARGET]].copy()\n",
                "    res_h['Pred_Hybrid'] = y_pred_h\n",
                "    predictions_hybrid.append(res_h)\n",
                "    \n",
                "    # Update Next Lag (Hybrid)\n",
                "    if next_year <= TEST_END_YEAR:\n",
                "        pred_map_h = dict(zip(current_year_hb['Entity'], y_pred_h))\n",
                "        # Scale using Hybrid Data stats\n",
                "        pred_map_h_scaled = {k: (v - target_mean_hb) / target_std_hb for k, v in pred_map_h.items()}\n",
                "        \n",
                "        mask_next_h = df_test_hb['Year'] == next_year\n",
                "        next_ents_h = df_test_hb.loc[mask_next_h, 'Entity']\n",
                "        updated_lags_h = next_ents_h.map(pred_map_h_scaled).fillna(df_test_hb.loc[mask_next_h, LAG_TARGET])\n",
                "        df_test_hb.loc[mask_next_h, LAG_TARGET] = updated_lags_h\n",
                "\n",
                "# Merge Results\n",
                "df_res_global = pd.concat(predictions_global)\n",
                "df_res_hybrid = pd.concat(predictions_hybrid)\n",
                "final_comparison = pd.merge(\n",
                "    df_res_global[['Entity', 'Year', TARGET, 'Pred_Global']],\n",
                "    df_res_hybrid[['Entity', 'Year', 'Pred_Hybrid']],\n",
                "    on=['Entity', 'Year']\n",
                ")\n",
                "print(\"\\nHoàn tất forecast.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation & Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_metrics(df, true_col, pred_col, label):\n",
                "    # Store APE in specific column\n",
                "    true_safe = df[true_col].replace(0, 1e-6)\n",
                "    df[f'APE_{label}'] = np.abs((df[true_col] - df[pred_col]) / true_safe) * 100\n",
                "    \n",
                "    mse = mean_squared_error(df[true_col], df[pred_col])\n",
                "    rmse = np.sqrt(mse)\n",
                "    mae = mean_absolute_error(df[true_col], df[pred_col])\n",
                "    r2 = r2_score(df[true_col], df[pred_col])\n",
                "    median_mape = df.groupby('Entity')[f'APE_{label}'].mean().median()\n",
                "    \n",
                "    return rmse, mae, r2, median_mape\n",
                "\n",
                "rmse_g, mae_g, r2_g, mape_g = calculate_metrics(final_comparison, TARGET, 'Pred_Global', 'Global')\n",
                "rmse_h, mae_h, r2_h, mape_h = calculate_metrics(final_comparison, TARGET, 'Pred_Hybrid', 'Hybrid')\n",
                "\n",
                "print(\"=== KẾT QUẢ ĐÁNH GIÁ (RECURSIVE 2015-2019) ===\")\n",
                "print(f\"{'Metric':<15} | {'Global Model':<15} | {'Hybrid Model':<15} | {'Cải thiện':<10}\")\n",
                "print(\"-\"*70)\n",
                "print(f\"{'RMSE':<15} | {rmse_g:,.2f}        | {rmse_h:,.2f}         | {(rmse_g - rmse_h)/rmse_g*100:+.2f}%\")\n",
                "print(f\"{'MAE':<15} | {mae_g:,.2f}        | {mae_h:,.2f}         | {(mae_g - mae_h)/mae_g*100:+.2f}%\")\n",
                "print(f\"{'Median MAPE':<15} | {mape_g:.2f}%          | {mape_h:.2f}%           | {(mape_g - mape_h)/mape_g*100:+.2f}%\")\n",
                "print(f\"{'R2 Score':<15} | {r2_g:.4f}          | {r2_h:.4f}           | {(r2_h - r2_g):+.4f}\")\n",
                "\n",
                "# 5.1 Global Trend\n",
                "global_trend = final_comparison.groupby('Year')[[TARGET, 'Pred_Global', 'Pred_Hybrid']].sum().reset_index()\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(global_trend['Year'], global_trend[TARGET], label='Actual', marker='o', linewidth=2, color='black')\n",
                "plt.plot(global_trend['Year'], global_trend['Pred_Global'], label='Global Baseline', marker='s', linestyle='--', color='blue')\n",
                "plt.plot(global_trend['Year'], global_trend['Pred_Hybrid'], label='Hybrid Model', marker='^', linestyle='--', color='red')\n",
                "plt.title('Global Recursive Forecasting (2015-2019)', fontsize=16)\n",
                "plt.xlabel('Year')\n",
                "plt.ylabel('Total CO2 Emissions (kt)')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()\n",
                "\n",
                "# 5.2 Top Countries\n",
                "countries = ['China', 'United States', 'India', 'Vietnam']\n",
                "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
                "axes = axes.flatten()\n",
                "for i, country in enumerate(countries):\n",
                "    country_data = final_comparison[final_comparison['Entity'] == country]\n",
                "    if len(country_data) > 0:\n",
                "        ax = axes[i]\n",
                "        ax.plot(country_data['Year'], country_data[TARGET], label='Actual', marker='o', color='black')\n",
                "        ax.plot(country_data['Year'], country_data['Pred_Global'], label='Global Baseline', linestyle='--', color='blue')\n",
                "        ax.plot(country_data['Year'], country_data['Pred_Hybrid'], label='Hybrid Model', linestyle='--', color='red')\n",
                "        ax.set_title(f'Recursive Forecast: {country}')\n",
                "        ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# 5.3 Error Dist\n",
                "ape_data = final_comparison.melt(id_vars=['Entity', 'Year'], value_vars=['APE_Global', 'APE_Hybrid'], var_name='Model', value_name='APE')\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(data=ape_data, x='Model', y='APE', showfliers=False)\n",
                "plt.title('APE Distribution', fontsize=16)\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}