# Global Energy & CO2 Emissions Forecasting Report

## 1. Project Objective
The goal of this project is to model and forecast **CO2 Emissions** (kt) for various countries based on global energy and economic indicators (GDP, Renewable Energy Share, Access to Electricity, etc.).
The core challenge identified was distinguishing between **Interpolation** (filling missing data points) and true **Forecasting** (predicting future trends).

---

## 2. Data Visualization & Evidence-Based Decisions

> [!IMPORTANT]
> Má»i quyáº¿t Ä‘á»‹nh tiá»n xá»­ lÃ½ trong dá»± Ã¡n nÃ y Ä‘á»u Ä‘Æ°á»£c **chá»©ng minh báº±ng dá»¯ liá»‡u** (Data-Driven), khÃ´ng pháº£i cáº£m tÃ­nh. Pháº§n nÃ y trÃ¬nh bÃ y cÃ¡c phÃ¢n tÃ­ch trá»±c quan lÃ m cÆ¡ sá»Ÿ cho cÃ¡c quyáº¿t Ä‘á»‹nh Ä‘Ã³.

---

### 2.1. PhÃ¢n tÃ­ch Dá»¯ liá»‡u Thiáº¿u (Missing Values Analysis)

![Missing Data by Column](figures/missing_by_column.png)

**Quan sÃ¡t:**
- **Cá»™t cÃ³ váº¥n Ä‘á» (>30% thiáº¿u)**: `Financial flows to developing countries`, `Renewables (% equivalent primary energy)` cÃ³ tá»· lá»‡ thiáº¿u cao.
- **Cá»™t á»•n Ä‘á»‹nh**: CÃ¡c biáº¿n kinh táº¿ cá»‘t lÃµi nhÆ° `GDP per capita`, `Access to electricity` cÃ³ tá»· lá»‡ thiáº¿u tháº¥p (<10%).

**Quyáº¿t Ä‘á»‹nh:**
| TÃ¬nh huá»‘ng | PhÆ°Æ¡ng phÃ¡p | LÃ½ do |
|---|---|---|
| Thiáº¿u lÃ¡c Ä‘Ã¡c giá»¯a chuá»—i | **Interpolation** (Ná»™i suy) | PhÃ¹ há»£p cho Time-series, giá»¯ tÃ­nh liÃªn tá»¥c |
| Thiáº¿u Ä‘áº§u chuá»—i | **Backfill** | Giáº£ Ä‘á»‹nh xu hÆ°á»›ng á»•n Ä‘á»‹nh |
| Thiáº¿u >50% cá»™t | **Log Transform + Median** | Giáº£m áº£nh hÆ°á»Ÿng cá»§a outliers |

---

### 2.2. PhÃ¢n tÃ­ch Cháº¥t lÆ°á»£ng Dá»¯ liá»‡u theo Quá»‘c gia

![Data Quality Analysis](figures/data_quality_analysis.png)

**Quan sÃ¡t:**
- **Trá»¥c trÃ¡i (Histogram)**: Äa sá»‘ quá»‘c gia cÃ³ **Ä‘á»§ 21 nÄƒm** dá»¯ liá»‡u (2000-2020). Chá»‰ má»™t sá»‘ Ã­t Ä‘áº£o nhá» cÃ³ <10 nÄƒm.
- **Trá»¥c pháº£i (Scatter)**: CÃ¡c cÆ°á»ng quá»‘c (China, USA, India) náº±m á»Ÿ gÃ³c trÃªn pháº£i - vá»«a cÃ³ Ä‘á»§ dá»¯ liá»‡u, vá»«a phÃ¡t tháº£i lá»›n.
- **NgÆ°á»¡ng 15 nÄƒm** (Ä‘Æ°á»ng Ä‘á»): Cáº¯t bá» ~5% quá»‘c gia cÃ³ dá»¯ liá»‡u khÃ´ng Ä‘á»§ dÃ i Ä‘á»ƒ há»c Time-series.

**Quyáº¿t Ä‘á»‹nh:**
```
QUY Táº®C: Chá»‰ giá»¯ quá»‘c gia cÃ³ >= 15 nÄƒm dá»¯ liá»‡u
WHITELIST Tá»° NHIÃŠN: KhÃ´ng cáº§n hard-code danh sÃ¡ch G20
Káº¿t quáº£: 171/176 quá»‘c gia Ä‘Æ°á»£c giá»¯ láº¡i (97%)
```

> [!NOTE]
> ÄÃ¢y lÃ  cÃ¡ch tiáº¿p cáº­n **Data-Driven** thay vÃ¬ hard-code whitelist. CÃ¡c nÆ°á»›c lá»›n (USA, China, UK, France...) tá»± Ä‘á»™ng Ä‘Æ°á»£c giá»¯ láº¡i vÃ¬ há» cÃ³ Ä‘á»§ dá»¯ liá»‡u.

---

### 2.3. PhÃ¢n tÃ­ch Skewness - Justify Log Transform

![Skewness Analysis](figures/skewness_analysis.png)

**Quan sÃ¡t:**
| Biáº¿n | Skewness Gá»‘c | Skewness sau Log | Cáº§n Log? |
|---|---|---|---|
| CO2 Emissions | ~8.5 | ~0.5 | âœ… CÃ³ thá»ƒ, nhÆ°ng lÃ  Target nÃªn KHÃ”NG |
| GDP per capita | ~3.2 | ~-0.3 | âœ… CÃ³ |
| Financial flows | ~12.1 | ~0.8 | âœ… **Báº®T BUá»˜C** |
| Renewables | ~2.8 | ~0.1 | âœ… CÃ³ |

**Quyáº¿t Ä‘á»‹nh:**
- **Ãp dá»¥ng Log Transform**: `Financial flows`, `Renewables` (Skewness > 2)
- **KHÃ”NG Ã¡p dá»¥ng cho CO2 (Target)**: Giá»¯ nguyÃªn Ä‘á»ƒ káº¿t quáº£ dá»± bÃ¡o cÃ³ Ã½ nghÄ©a váº­t lÃ½ (táº¥n khÃ­ tháº£i)

---

### 2.4. PhÃ¢n tÃ­ch Outliers - Signal vs Noise

![Outlier Analysis](figures/outlier_analysis.png)

**Quan sÃ¡t:**
- **Top 10 "Outliers"**: China, USA, India, Russia, Japan, Germany...
- ÄÃ¢y lÃ  **SIGNAL (TÃ­n hiá»‡u quan trá»ng)**, khÃ´ng pháº£i **NOISE (Nhiá»…u)**.
- Náº¿u dÃ¹ng IQR, sáº½ loáº¡i bá» 90% lÆ°á»£ng phÃ¡t tháº£i toÃ n cáº§u!

**Quyáº¿t Ä‘á»‹nh:**
```
âŒ KHÃ”NG dÃ¹ng IQR cho Target (CO2)
   LÃ½ do: Top emitters = Top outliers = SIGNAL

âœ… Sá»¬ Dá»¤NG: Quy táº¯c Data Quality (Sá»‘ nÄƒm dá»¯ liá»‡u)
   LÃ½ do: Loáº¡i quá»‘c gia thiáº¿u dá»¯ liá»‡u, KHÃ”NG loáº¡i quá»‘c gia lá»›n
```

> [!WARNING]
> ÄÃ¢y lÃ  sai láº§m phá»• biáº¿n trong Data Science: Ãp dá»¥ng IQR mÃ¹ quÃ¡ng mÃ  khÃ´ng visualize trÆ°á»›c. Káº¿t quáº£ lÃ  model Ä‘Æ°á»£c train toÃ n trÃªn Ä‘áº£o nhá», bá» lá»¡ xu hÆ°á»›ng toÃ n cáº§u.

---

### 2.5. PhÃ¢n tÃ­ch Äa cá»™ng tuyáº¿n (Multicollinearity)

![Correlation Matrix](figures/correlation_matrix.png)

**Quan sÃ¡t:**
| Cáº·p biáº¿n | TÆ°Æ¡ng quan | Quyáº¿t Ä‘á»‹nh |
|---|---|---|
| GDP per capita â†” Primary Energy | **0.92** | Loáº¡i GDP (Energy cÃ³ Ã½ nghÄ©a váº­t lÃ½ hÆ¡n vá»›i CO2) |
| Access to electricity â†” Access to clean fuels | **0.89** | Loáº¡i 1 trong 2 |
| Year â†” GDP per capita | **0.35** | Giá»¯ cáº£ hai (tÆ°Æ¡ng quan tháº¥p) |

**Quyáº¿t Ä‘á»‹nh VIF (Variance Inflation Factor):**
```
LOáº I Bá» (VIF > 10):
  - gdp_per_capita
  - Access to electricity (% of population)
  - Access to clean fuels for cooking
  
GIá»® Láº I (Protected):
  - CO2_lag1 (Quan trá»ng nháº¥t cho Forecasting!)
  - Primary energy consumption per capita
```

---

### 2.6. Tá»•ng há»£p Chiáº¿n lÆ°á»£c Tiá»n xá»­ lÃ½

![Preprocessing Audit](figures/preprocessing_audit.png)

**Data Flow Summary:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     RAW DATA (176)      â”‚
â”‚   Kaggle Original       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“ -1 (Lag Features)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COMMON PREPROCESSED    â”‚
â”‚     (175 Countries)     â”‚
â”‚  + Lag-1, Median Impute â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“ -41 (Data Quality Filter)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    FINAL LR PREP        â”‚
â”‚     (134 Countries)     â”‚
â”‚  + VIF, Z-Score, No2020 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RETENTION RATE: 76.1%
```

---



## 3. PhÆ°Æ¡ng phÃ¡p & Pipeline Tiá»n xá»­ lÃ½

### 3.1. Tá»•ng quan Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           DATA FLOW PIPELINE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  RAW DATA (3649 rows Ã— 21 cols, 176 countries, 2000-2020)                  â”‚
â”‚      â†“                                                                      â”‚
â”‚  [COMMON PREPROCESSING]                                                     â”‚
â”‚      â”œâ”€â”€ Missing Imputation (Median)                                       â”‚
â”‚      â”œâ”€â”€ Lag Features (+4 cols: CO2_lag1, GDP_lag1, Energy_lag1, Growth_lag1)â”‚
â”‚      â””â”€â”€ -176 rows (first year má»—i nÆ°á»›c khÃ´ng cÃ³ Lag)                       â”‚
â”‚      â†“                                                                      â”‚
â”‚  COMMON PREPROCESSED (3473 rows Ã— 25 cols, 175 countries)                  â”‚
â”‚      â†“                                                                      â”‚
â”‚  [ALGORITHM-SPECIFIC PREPROCESSING]                                         â”‚
â”‚      â”œâ”€â”€ LINEAR REGRESSION â†’ 2309 rows Ã— 193 cols                          â”‚
â”‚      â”œâ”€â”€ SVR              â†’ 3473 rows Ã— 198 cols                          â”‚
â”‚      â””â”€â”€ XGBOOST          â†’ 3473 rows Ã— 25 cols                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 3.2. Tiá»n xá»­ lÃ½ Chung (Common Preprocessing)

ÄÃ¢y lÃ  cÃ¡c bÆ°á»›c Ã¡p dá»¥ng cho **Táº¤T Cáº¢** thuáº­t toÃ¡n:

#### 3.2.1. Xá»­ lÃ½ Dá»¯ liá»‡u Thiáº¿u (Missing Values)
| PhÆ°Æ¡ng phÃ¡p | Ãp dá»¥ng cho | LÃ½ do |
|---|---|---|
| **Entity-Specific Interpolation** | Thiáº¿u lÃ¡c Ä‘Ã¡c giá»¯a chuá»—i | Duy trÃ¬ tÃ­nh liÃªn tá»¥c cá»§a chuá»—i thá»i gian cho tá»«ng quá»‘c gia |
| **Median Imputation (Fallback)** | Thiáº¿u Ä‘áº§u/cuá»‘i chuá»—i | Robust vá»›i Outliers, dÃ¹ng khi khÃ´ng thá»ƒ ná»™i suy |
| **Forward Fill** | Cá»™t cÃ³ xu hÆ°á»›ng á»•n Ä‘á»‹nh | Giá»¯ tÃ­nh liÃªn tá»¥c khi interpolation khÃ´ng kháº£ thi |

> [!NOTE]
> **Chiáº¿n lÆ°á»£c 2 lá»›p**: Interpolation lÃ  phÆ°Æ¡ng phÃ¡p chÃ­nh (nhÆ° Ä‘Ã£ phÃ¢n tÃ­ch á»Ÿ Section 2.1). Median chá»‰ dÃ¹ng lÃ m Fallback cho cÃ¡c trÆ°á»ng há»£p khÃ´ng thá»ƒ ná»™i suy (thiáº¿u Ä‘áº§u/cuá»‘i chuá»—i).

#### 3.2.2. Táº¡o Äáº·c trÆ°ng Lag (Lag Features)

| Feature | CÃ´ng thá»©c | Ã nghÄ©a |
|---|---|---|
| `CO2_lag1` | $CO2_{t-1}$ | LÆ°á»£ng phÃ¡t tháº£i nÄƒm trÆ°á»›c (Predictor máº¡nh nháº¥t!) |
| `GDP_lag1` | $GDP_{t-1}$ | GDP bÃ¬nh quÃ¢n nÄƒm trÆ°á»›c |
| `Energy_lag1` | $Energy_{t-1}$ | TiÃªu thá»¥ nÄƒng lÆ°á»£ng nÄƒm trÆ°á»›c |
| `GDP_Growth_lag1` | $Growth_{t-1}$ | Tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng GDP nÄƒm trÆ°á»›c |

> [!IMPORTANT]
> **CO2_lag1 lÃ  feature quan trá»ng nháº¥t** vÃ¬ lÆ°á»£ng phÃ¡t tháº£i nÄƒm nay phá»¥ thuá»™c ráº¥t máº¡nh vÃ o nÄƒm trÆ°á»›c (Autocorrelation cao). ÄÃ¢y lÃ  lÃ½ do model Ä‘áº¡t RÂ² ~0.999.

---

### 3.3. Tiá»n xá»­ lÃ½ cho Linear Regression (Ridge)

| BÆ°á»›c | PhÆ°Æ¡ng phÃ¡p | Chi tiáº¿t | LÃ½ do |
|---|---|---|---|
| **1. Log Transform** | `np.log1p(x)` | Ãp dá»¥ng cho `Financial flows`, `Renewables` | Giáº£m Skewness tá»« >8 xuá»‘ng <1 (xem Section 2.3) |
| **2. One-Hot Encoding** | `pd.get_dummies(drop_first=True)` | Táº¡o 175 cá»™t Entity_* | Capture country fixed-effects trong Panel Data |
| **3. Outlier Removal** | IQR (threshold=3.0) + Whitelist | Loáº¡i outliers NGOáº I TRá»ª 39 nÆ°á»›c lá»›n | Xem Section 2.4 - Top outliers = Top emitters = SIGNAL |
| **4. 2020 Removal** | Drop rows Year=2020 | Loáº¡i 175 rows nÄƒm 2020 | Dá»¯ liá»‡u 2020 cÃ³ váº¥n Ä‘á» cháº¥t lÆ°á»£ng |
| **5. VIF Removal** | Threshold VIF > 10 | Loáº¡i: GDP, Access to electricity, Access to clean fuels | Giáº£m Ä‘a cá»™ng tuyáº¿n (xem Section 2.5) |
| **6. Z-Score Scaling** | $(x - \mu) / \sigma$ | Ãp dá»¥ng cho táº¥t cáº£ numeric (trá»« Target, Entity_*) | Ridge Regression cáº§n features cÃ¹ng scale |

**Káº¿t quáº£ cuá»‘i cÃ¹ng**: 2309 rows Ã— 193 columns Ã— 134 countries

---

### 3.4. Tiá»n xá»­ lÃ½ cho SVR (Support Vector Regression)

| BÆ°á»›c | PhÆ°Æ¡ng phÃ¡p | Chi tiáº¿t | LÃ½ do |
|---|---|---|---|
| **1. Log Transform** | `np.log1p(x)` | Giá»‘ng Linear Regression | Kernel RBF cáº§n phÃ¢n phá»‘i Ä‘á»u |
| **2. One-Hot Encoding** | `pd.get_dummies(drop_first=True)` | Giá»‘ng Linear Regression | Cáº§n numeric input |
| **3. KHÃ”NG Outlier Removal** | Giá»¯ nguyÃªn | Giá»¯ táº¥t cáº£ 175 countries | SVR vá»›i RBF kernel inherently robust vá»›i outliers |
| **4. Robust Scaling** | $(x - median) / IQR$ | Thay Z-Score | Robust Scaler khÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers |

**Káº¿t quáº£ cuá»‘i cÃ¹ng**: 3473 rows Ã— 198 columns Ã— 175 countries

> [!TIP]
> SVR giá»¯ nhiá»u data hÆ¡n LR vÃ¬ nÃ³ khÃ´ng cáº§n loáº¡i outliers. Tuy nhiÃªn, káº¿t quáº£ cho tháº¥y SVR perform kÃ©m hÆ¡n LR trong task nÃ y (xem Section 4.1).

---

### 3.5. Tiá»n xá»­ lÃ½ cho XGBoost

| BÆ°á»›c | PhÆ°Æ¡ng phÃ¡p | Chi tiáº¿t | LÃ½ do |
|---|---|---|---|
| **1. KHÃ”NG Log Transform** | Giá»¯ giÃ¡ trá»‹ gá»‘c | Raw values | Trees tá»± Ä‘á»™ng handle skewed data trong quÃ¡ trÃ¬nh split |
| **2. Ordinal Encoding** | Entity â†’ Integer (0,1,2...) | 175 unique integers | Trees split trÃªn numeric efficiently |
| **3. KHÃ”NG Outlier Removal** | Giá»¯ nguyÃªn | Giá»¯ táº¥t cáº£ countries | Tree-based models robust vÃ¬ dÃ¹ng split, khÃ´ng dÃ¹ng distance |
| **4. KHÃ”NG Scaling** | Giá»¯ giÃ¡ trá»‹ gá»‘c | Raw values | Trees are **scale-invariant** (quyáº¿t Ä‘á»‹nh dá»±a trÃªn ordering, khÃ´ng magnitude) |

**Káº¿t quáº£ cuá»‘i cÃ¹ng**: 3473 rows Ã— 25 columns Ã— 175 countries

> [!WARNING]
> XGBoost Ä‘áº¡t RÂ² = 0.998 khi Random Split (Interpolation) nhÆ°ng **THá»¤ LÃ™I xuá»‘ng 0.793** khi Time-Series Split. LÃ½ do: Trees khÃ´ng thá»ƒ extrapolate xu hÆ°á»›ng tuyáº¿n tÃ­nh (xem Section 4.1).

---

### 3.6. So sÃ¡nh Tá»•ng há»£p 3 Thuáº­t toÃ¡n

| Äáº·c Ä‘iá»ƒm | Linear Regression | SVR | XGBoost |
|---|---|---|---|
| **Sá»‘ rows** | 2309 | 3473 | 3473 |
| **Sá»‘ columns** | 193 | 198 | 25 |
| **Sá»‘ countries** | 134 | 175 | 175 |
| **Encoding** | One-Hot | One-Hot | Ordinal |
| **Scaling** | Z-Score | Robust | None |
| **Outlier Handling** | Removed + Whitelist | Kept | Kept |
| **Log Transform** | Yes | Yes | No |

---

### 3.7. Chiáº¿n lÆ°á»£c ÄÃ¡nh giÃ¡ (Evaluation Strategy)

#### 3.7.1. Phase 0: Random Split vs Time-Series Split

| PhÆ°Æ¡ng phÃ¡p | MÃ´ táº£ | Má»¥c Ä‘Ã­ch |
|---|---|---|
| **Random Split** | Shuffle ngáº«u nhiÃªn, chia 80/20 | Test kháº£ nÄƒng **Ná»™i suy** (Interpolation) |
| **Time-Series Split** | Train < 2015, Test >= 2015 | Test kháº£ nÄƒng **Dá»± bÃ¡o** (Forecasting) - **TIÃŠU CHUáº¨N THá»°C Sá»°** |

> [!CAUTION]
> Random Split lÃ  **BáºªY INTERPOLATION**! Model cÃ³ thá»ƒ "nhÃ¬n tháº¥y" 2016 khi train, rá»“i "dá»± Ä‘oÃ¡n" 2015. ÄÃ¢y lÃ  **Data Leakage**, khÃ´ng pháº£i forecasting.

#### 3.7.2. Phase 1: Global Linear Regression (Baseline)

- **MÃ´ hÃ¬nh**: Ridge Regression (Î±=1.0)
- **Train**: 2001-2014 (14 nÄƒm)
- **Test**: 2015-2019 (5 nÄƒm)
- **Metric**: RÂ², RMSE, Median MAPE

#### 3.7.3. Phase 3: Cluster-Based Linear Regression

- **Chiáº¿n lÆ°á»£c**: "Chia Ä‘á»ƒ trá»‹" - NhÃ³m cÃ¡c nÆ°á»›c tÆ°Æ¡ng tá»± Ä‘á»ƒ train model riÃªng
- **Clustering**: K-Means (K=3) trÃªn GDP, Energy, CO2
- **Anti-Leakage**: Cluster Ä‘Æ°á»£c gÃ¡n dá»±a trÃªn dá»¯ liá»‡u 2014, Ã¡p dá»¥ng cá»‘ Ä‘á»‹nh cho 2015-2020
- **Káº¿t quáº£**: Xem Section 4.4

#### 3.7.4. Phase 4: Recursive Forecasting (Stress Test)

- **Má»¥c tiÃªu**: Kiá»ƒm tra model bá»‹ "sai chá»“ng sai" nhÆ° tháº¿ nÃ o
- **PhÆ°Æ¡ng phÃ¡p**: DÃ¹ng $\hat{Y}_{t-1}$ (dá»± Ä‘oÃ¡n) thay vÃ¬ $Y_{t-1}$ (thá»±c táº¿) lÃ m input
- **Káº¿t quáº£**: RÂ² giáº£m tá»« 0.99 â†’ 0.44 sau 5 nÄƒm (xem Section 4.7)

#### 3.7.5. Phase 5: Real-World Validation (2020-2023)

- **Má»¥c tiÃªu**: Chá»©ng minh model hoáº¡t Ä‘á»™ng ngoÃ i lab
- **Nguá»“n dá»¯ liá»‡u**: World Bank API (live)
- **Ground Truth**: OWID (Our World In Data)
- **Káº¿t quáº£**: RÂ² = 0.989 trÃªn 106 quá»‘c gia (xem Section 4.9)

---



## 4. Káº¿t quáº£ & PhÃ¢n tÃ­ch (Results & Analysis)

### 4.1. Phase 0: Random Split vs Time-Series Split ("Báº«y Ná»™i suy")

> [!CAUTION]
> ÄÃ¢y lÃ  thÃ­ nghiá»‡m quan trá»ng nháº¥t Ä‘á»ƒ chá»©ng minh: **Random Split lÃ  Data Leakage** trong bÃ i toÃ¡n dá»± bÃ¡o chuá»—i thá»i gian.

**Thiáº¿t láº­p thÃ­ nghiá»‡m:**
- **Random Split**: Shuffle ngáº«u nhiÃªn táº¥t cáº£ cÃ¡c nÄƒm, chia 80/20
- **Time-Series Split**: Train < 2015, Test >= 2015 (KhÃ´ng nhÃ¬n tháº¥y tÆ°Æ¡ng lai)

| Thuáº­t toÃ¡n | Random RÂ² | Random MAPE | TS RÂ² | TS MAPE | Sá»¥t giáº£m (RÂ²) | TÄƒng lá»—i (MAPE) | Nháº­n xÃ©t |
|---|---|---|---|---|---|---|---|
| **SVR** | -0.05 | N/A | -0.04 | N/A | N/A | N/A | âŒ Tháº¥t báº¡i hoÃ n toÃ n |
| **XGBoost** | **0.998** | **13.09%** | **0.793** | **30.74%** | -20.5% | **+135%** | âš ï¸ KhÃ´ng thá»ƒ extrapolate |
| **Linear Regression** | **0.999** | **35.82%** | **0.999** | **50.08%** | 0% | **+40%** | âœ… HoÃ n toÃ n Robust |

**PhÃ¢n tÃ­ch chi tiáº¿t:**

#### ğŸ”´ SVR: Tháº¥t báº¡i (RÂ² Ã¢m)
- **NguyÃªn nhÃ¢n**: SVR vá»›i RBF kernel khÃ´ng Ä‘Æ°á»£c tune hyperparameters (C, gamma)
- **Háº­u quáº£**: Model dá»± Ä‘oÃ¡n gáº§n nhÆ° khÃ´ng liÃªn quan Ä‘áº¿n thá»±c táº¿
- **BÃ i há»c**: SVR cáº§n tuning cáº©n tháº­n, khÃ´ng pháº£i plug-and-play

#### ğŸŸ¡ XGBoost: Báº«y Ná»™i suy
- **Hiá»‡n tÆ°á»£ng**: Random Split Ä‘áº¡t 0.998, nhÆ°ng Time-Series chá»‰ cÃ²n 0.793
- **NguyÃªn nhÃ¢n khoa há»c**: 
  - Trees chia feature space thÃ nh cÃ¡c "há»™p" (nodes)
  - Khi test data cÃ³ giÃ¡ trá»‹ cao hÆ¡n training (GDP 2020 > max GDP 2014), tree chá»‰ cÃ³ thá»ƒ dá»± Ä‘oÃ¡n báº±ng giÃ¡ trá»‹ max Ä‘Ã£ tháº¥y
  - Káº¿t quáº£: **"Flat line" prediction** - khÃ´ng thá»ƒ extrapolate xu hÆ°á»›ng tÄƒng
- **Minh há»a**: Náº¿u GDP 2014 = 50,000, GDP 2020 = 65,000, XGBoost sáº½ dá»± Ä‘oÃ¡n CO2 nhÆ° thá»ƒ GDP = 50,000

> [!NOTE]
> **Táº¡i sao XGBoost cÃ³ MAPE (30%) tá»‘t hÆ¡n LR (50%), nhÆ°ng RÂ² (0.79) láº¡i tá»‡ hÆ¡n LR (0.99)?**
>
> ÄÃ¢y lÃ  vÃ­ dá»¥ Ä‘iá»ƒn hÃ¬nh vá» **Metric Sensitivity**:
> 1. **RÂ² (Global Fit)**: Bá»‹ chi phá»‘i bá»Ÿi **Outliers (China, USA)**.
>    - LR dá»± Ä‘oÃ¡n ráº¥t Ä‘Ãºng xu hÆ°á»›ng tÄƒng cá»§a China/USA â†’ RÂ² ráº¥t cao (0.99).
>    - XGBoost bá»‹ lá»—i "Flatline" vá»›i China/USA â†’ Sai sá»‘ tuyá»‡t Ä‘á»‘i lá»›n â†’ RÂ² tá»¥t xuá»‘ng 0.79.
> 2. **Median MAPE (Local Fit)**: "DÃ¢n chá»§" cho má»i quá»‘c gia.
>    - Vá»›i Ä‘a sá»‘ cÃ¡c nÆ°á»›c nhá»/Ä‘ang phÃ¡t triá»ƒn (khÃ´ng tÄƒng trÆ°á»Ÿng nÃ³ng), Ä‘Æ°á»ng tháº³ng (LR) thÆ°á»ng dá»± bÃ¡o quÃ¡ Ä‘Ã  (over-extrapolate).
>    - XGBoost (dÃ¹ bá»‹ flatline) láº¡i vÃ´ tÃ¬nh Ä‘Æ°a ra dá»± bÃ¡o "an toÃ n" hÆ¡n cho cÃ¡c nÆ°á»›c nhá» nÃ y, dáº«n Ä‘áº¿n MAPE trung vá»‹ tháº¥p hÆ¡n.
>
> â†’ **Káº¿t luáº­n**: LR tá»‘t cho Global Trend (RÂ²), XGBoost tá»‘t cho Local nuances (MAPE). Hybrid Model sinh ra Ä‘á»ƒ káº¿t há»£p cáº£ hai!

#### ğŸŸ¢ Linear Regression: Robust hoÃ n toÃ n
- **Hiá»‡n tÆ°á»£ng**: KHÃ”NG sá»¥t giáº£m khi chuyá»ƒn tá»« Random â†’ Time-Series
- **NguyÃªn nhÃ¢n khoa há»c**:
  - Linear model há»c há»‡ sá»‘ $\beta$: $CO2 = \beta_1 \cdot GDP + \beta_2 \cdot Energy + ...$
  - Há»‡ sá»‘ nÃ y Ã¡p dá»¥ng Ä‘Æ°á»£c cho Má»ŒI giÃ¡ trá»‹ input (extrapolation tá»± nhiÃªn)
  - CO2 emissions tuÃ¢n theo xu hÆ°á»›ng tuyáº¿n tÃ­nh trong ngáº¯n-trung háº¡n (5-10 nÄƒm)
- **Káº¿t luáº­n**: **Linear Regression lÃ  lá»±a chá»n tá»‘i Æ°u cho bÃ i toÃ¡n forecasting nÃ y**

---

### 4.2. Phase 1: Global Linear Regression (Baseline) - Káº¿t quáº£ ChÃ­nh

**Cáº¥u hÃ¬nh:**
- **MÃ´ hÃ¬nh**: Ridge Regression (Î± = 1.0)
- **Train**: 2001-2014 (1692 observations)
- **Test**: 2015-2019 (617 observations)
- **Sá»‘ quá»‘c gia**: 128 countries

| Metric | Káº¿t quáº£ | PhÃ¢n tÃ­ch |
|---|---|---|
| **RÂ² Score** | **0.9993** | Giáº£i thÃ­ch 99.93% phÆ°Æ¡ng sai - Gáº§n nhÆ° hoÃ n háº£o |
| **Median MAPE** | **22.9%** | Sai sá»‘ trung vá»‹ 22.9% cho má»™t quá»‘c gia Ä‘iá»ƒn hÃ¬nh |
| **RMSE** | **28,177 kt** | Sai sá»‘ tuyá»‡t Ä‘á»‘i cao do China/USA cÃ³ giÃ¡ trá»‹ ráº¥t lá»›n |
| **Mean MAPE** | **631.9%** | Bá»‹ kÃ©o cao bá»Ÿi cÃ¡c Ä‘áº£o nhá» (Tuvalu, Nauru) |

> [!IMPORTANT]
> **Táº¡i sao Median MAPE (22.9%) quan trá»ng hÆ¡n Mean MAPE (631.9%)?**
> - Mean bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi cÃ¡c nÆ°á»›c nhá» nhÆ° Tuvalu (CO2 = 10 kt, Predicted = 10,000 kt â†’ APE = 100,000%)
> - Median Ä‘áº¡i diá»‡n cho "má»™t quá»‘c gia Ä‘iá»ƒn hÃ¬nh" - cÃ´ng báº±ng hÆ¡n

**Ã nghÄ©a káº¿t quáº£:**
- RÂ² = 0.999 chá»©ng minh model **báº¯t Ä‘Æ°á»£c xu hÆ°á»›ng toÃ n cáº§u** ráº¥t tá»‘t
- Median MAPE = 22.9% nghÄ©a lÃ  **má»™t quá»‘c gia Ä‘iá»ƒn hÃ¬nh** cÃ³ sai sá»‘ khoáº£ng 23%
- ÄÃ¢y lÃ  káº¿t quáº£ **ráº¥t tá»‘t** cho bÃ i toÃ¡n dá»± bÃ¡o kinh táº¿ vÄ© mÃ´ 5 nÄƒm

---

### 4.3. PhÃ¢n tÃ­ch ChuyÃªn sÃ¢u: Táº¡i sao Linear Regression tháº¯ng?

#### A. Báº£n cháº¥t cá»§a Dá»¯ liá»‡u CO2

CO2 emissions lÃ  chá»‰ sá»‘ **kinh táº¿ vÄ© mÃ´** vá»›i cÃ¡c Ä‘áº·c Ä‘iá»ƒm:

1. **Autocorrelation cao**: CO2 nÄƒm nay â‰ˆ CO2 nÄƒm trÆ°á»›c (Ä‘Ã¢y lÃ  lÃ½ do CO2_lag1 quan trá»ng)
2. **Xu hÆ°á»›ng tuyáº¿n tÃ­nh ngáº¯n háº¡n**: Trong 5-10 nÄƒm, CO2 thÆ°á»ng tÄƒng/giáº£m theo Ä‘Æ°á»ng tháº³ng
3. **Driven by GDP**: TÆ°Æ¡ng quan máº¡nh vá»›i GDP per capita

```
CO2(t) â‰ˆ Î²â‚€ + Î²â‚Â·CO2(t-1) + Î²â‚‚Â·GDP(t) + Î²â‚ƒÂ·Entity_*
```

Linear Regression **hoÃ n háº£o** cho dáº¡ng dá»¯ liá»‡u nÃ y.

#### B. Táº¡i sao XGBoost tháº¥t báº¡i?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            XGBoost Extrapolation Problem                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚    CO2 â–²                                                           â”‚
â”‚        â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚   15M  â”‚                    â”‚ XGBoost: "Flat" â”‚                     â”‚
â”‚        â”‚              â—â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—                     â”‚
â”‚        â”‚           â—                          Actual continues up   â”‚
â”‚   10M  â”‚        â—                                                   â”‚
â”‚        â”‚     â—                                                      â”‚
â”‚        â”‚  â—                                                         â”‚
â”‚    5M  â”‚â—                                                           â”‚
â”‚        â”‚                                                            â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Year  â”‚
â”‚             2010   2014   â”‚   2015   2016   2017   2018   2019      â”‚
â”‚                     Train â”‚   Test                                  â”‚
â”‚                           â”‚                                         â”‚
â”‚  Trees predict max(training value) for OOD inputs                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### C. Simpson's Paradox vÃ  Clustering

**Giáº£ thuyáº¿t ban Ä‘áº§u**: NhÃ³m cÃ¡c nÆ°á»›c tÆ°Æ¡ng tá»± sáº½ giáº£m nhiá»…u (Simpson's Paradox)

**Thá»±c táº¿**: Clustering lÃ m Tá»† hÆ¡n! (Xem Section 4.4)

---

### 4.4. Phase 3: Cluster-Based Linear Regression

**Má»¥c tiÃªu**: Chia cÃ¡c quá»‘c gia thÃ nh nhÃ³m tÆ°Æ¡ng tá»± Ä‘á»ƒ train model riÃªng

**PhÆ°Æ¡ng phÃ¡p**: K-Means (K=3) dá»±a trÃªn GDP, Energy, CO2 cá»§a nÄƒm 2014

| Cluster | MÃ´ táº£ | RÂ² Score | Median MAPE | Sá»‘ nÆ°á»›c |
|---|---|---|---|---|
| **Cluster 0** | High Growth (China, India...) | 0.9967 | 45.2% | ~30 |
| **Cluster 1** | Developed (USA, Germany...) | 0.9865 | 12.1% | ~40 |
| **Cluster 2** | Developing (Africa, Islands...) | 0.7102 | 84.5% | ~60 |
| **Tá»•ng há»£p** | Weighted Average | **0.9968** | **66.3%** | ~130 |

**Nháº­n xÃ©t:**

> [!WARNING]
> **Clustering tÄƒng "Fairness Gap"!**
> - Cluster 1 (PhÃ¡t triá»ƒn): Chá»‰ 12% error - Ráº¥t tá»‘t
> - Cluster 2 (Äang phÃ¡t triá»ƒn): **84.5% error** - Ráº¥t tá»‡
> - ÄÃ¢y lÃ  **báº¥t cÃ´ng** - model phá»¥c vá»¥ tá»‘t nÆ°á»›c giÃ u, phá»¥c vá»¥ tá»‡ nÆ°á»›c nghÃ¨o

**NguyÃªn nhÃ¢n tháº¥t báº¡i "Chia Ä‘á»ƒ trá»‹":**

**"Small Pond, Big Fish" Problem:**
- Khi tÃ¡ch China vÃ o Cluster 0 (N=30), China chiáº¿m 90% variance â†’ Model overfit China
- Trong Global Model (N=1700+), China chá»‰ chiáº¿m 5% â†’ Model balanced hÆ¡n

**Káº¿t luáº­n**: âŒ Loáº¡i bá» Clustering, giá»¯ Global Model.

---

### 4.5. So sÃ¡nh Tá»•ng há»£p cÃ¡c PhÆ°Æ¡ng phÃ¡p

| Phase | PhÆ°Æ¡ng phÃ¡p | RÂ² | Median MAPE | Káº¿t luáº­n |
|---|---|---|---|---|
| **Phase 0** | Random Split (All) | 0.999 | - | âŒ Data Leakage |
| **Phase 1** | Global LR (Time-Split) | **0.9993** | **22.9%** | âœ… **BEST** |
| **Phase 3** | Cluster LR | 0.9968 | 66.3% | âŒ Unfair |
| **Phase 1** | XGBoost (Time-Split) | 0.793 | - | âŒ Can't extrapolate |
| **Phase 1** | SVR (Time-Split) | -0.04 | - | âŒ Failed |

**Winner: Global Linear Regression vá»›i Time-Series Split**

---



### 4.6. Phase 4: MÃ´ hÃ¬nh NÃ¢ng cao theo Quá»‘c gia (Experimental)

**Má»¥c tiÃªu**: Kiá»ƒm tra xem viá»‡c há»c "há»‡ sá»‘ riÃªng" (Slope) cho tá»«ng quá»‘c gia cÃ³ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c hay khÃ´ng.

**Giáº£ thuyáº¿t ban Ä‘áº§u**:
- Model hiá»‡n táº¡i (Panel Data vá»›i One-Hot) há»c **Intercept riÃªng** cho má»—i nÆ°á»›c (level CO2 khÃ¡c nhau)
- NhÆ°ng buá»™c **táº¥t cáº£** nÆ°á»›c chia sáº» cÃ¹ng má»™t **Slope** (tá»‘c Ä‘á»™ tÄƒng CO2 theo GDP)
- CÃ³ thá»ƒ China vÃ  USA cáº§n slope khÃ¡c nhau?

---

#### ThÃ­ nghiá»‡m 1: Linear Mixed Effects Model (LMM)

**PhÆ°Æ¡ng phÃ¡p**: Cho phÃ©p Random Slopes cho GDP vÃ  Energy theo tá»«ng quá»‘c gia

```
Formula: CO2 ~ GDP + Energy (Fixed Effects) + (1 + GDP + Energy | Entity) (Random Effects)
```

**Káº¿t quáº£ tá»« `notebooks/11_Advanced_Country_Modeling.ipynb`**:

| Metric | GiÃ¡ trá»‹ |
|---|---|
| **RÂ² Score** | **0.0376** âŒ |
| Converged | Yes |
| Observations | 1558 |
| Groups (Countries) | 131 |

> [!CAUTION]
> **LMM tháº¥t báº¡i hoÃ n toÃ n!** RÂ² = 0.04 nghÄ©a lÃ  model gáº§n nhÆ° khÃ´ng giáº£i thÃ­ch Ä‘Æ°á»£c gÃ¬.

**NguyÃªn nhÃ¢n tháº¥t báº¡i**:
1. **Dá»¯ liá»‡u quÃ¡ Ã­t**: Má»—i nÆ°á»›c chá»‰ cÃ³ ~12 nÄƒm (sau khi loáº¡i 2000 do Lag, 2020 do quality)
2. **QuÃ¡ nhiá»u tham sá»‘**: 131 countries Ã— 3 random effects = ~400 parameters
3. **Overfitting paradox**: Model cá»‘ gáº¯ng fit quÃ¡ nhiá»u slopes riÃªng â†’ khÃ´ng generalize Ä‘Æ°á»£c

---

#### ThÃ­ nghiá»‡m 2: Interaction Terms (Manual Slopes)

**PhÆ°Æ¡ng phÃ¡p**: ThÃªm thá»§ cÃ´ng cÃ¡c interaction features cho 8 nÆ°á»›c lá»›n nháº¥t

```python
TOP_ENTITIES = ['China', 'United States', 'India', 'Japan', 
                'Russian Federation', 'Germany', 'Brazil', 'Canada']

# Táº¡o features: GDP Ã— Is_China, Energy Ã— Is_China, ...
```

**Káº¿t quáº£**:

| Model | RÂ² Score | Sá»‘ Features |
|---|---|---|
| Global LR (Benchmark) | **0.7817** | 23 |
| Interaction Ridge (Top 8 Slopes) | **0.7715** | 38 |
| ChÃªnh lá»‡ch | **-0.01** | +15 features |

> [!NOTE]
> ThÃªm 15 features interaction nhÆ°ng RÂ² giáº£m nháº¹ 0.01. KhÃ´ng Ä‘Ã¡ng Ä‘á»ƒ phá»©c táº¡p hÃ³a model.

---

#### Káº¿t luáº­n Phase 4

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SO SÃNH CÃC PHÆ¯Æ NG PHÃP SLOPE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Model                          â”‚ RÂ²     â”‚ Nháº­n xÃ©t                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Global LR (Shared Slope)       â”‚ 0.782  â”‚ âœ… BEST - Simple & Robust         â”‚
â”‚ LMM (Random Slopes)            â”‚ 0.038  â”‚ âŒ Failed - Overfitting           â”‚
â”‚ Interaction (Manual Slopes)    â”‚ 0.772  â”‚ âš ï¸ KhÃ´ng cáº£i thiá»‡n               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Insight khoa há»c**:
- Má»‘i quan há»‡ **GDP â†’ CO2** lÃ  **Universal** (giá»‘ng nhau cho táº¥t cáº£ cÃ¡c nÆ°á»›c)
- $\beta_{GDP}$ â‰ˆ 30,000 kt/unit cÃ³ nghÄ©a: Khi GDP tÄƒng 1 unit, CO2 thÆ°á»ng tÄƒng ~30,000 kt
- Äiá»u nÃ y Ä‘Ãºng cho cáº£ China (tÄƒng nhanh) vÃ  Germany (tÄƒng cháº­m) - chá»‰ khÃ¡c nhau vá» **scale** (Intercept), khÃ´ng khÃ¡c vá» **tá»‘c Ä‘á»™** (Slope)

**Quyáº¿t Ä‘á»‹nh final**: âœ… Giá»¯ **Global Panel Model** (Shared Slope + Country Intercepts)



### 4.7. Phase 2: Hyperparameter Tuning (GridSearchCV)

**Má»¥c tiÃªu**: TÃ¬m tham sá»‘ tá»‘i Æ°u cho Ridge vÃ  XGBoost sá»­ dá»¥ng **TimeSeriesSplit** Ä‘á»ƒ trÃ¡nh Data Leakage.

**PhÆ°Æ¡ng phÃ¡p tá»« `notebooks/6_Phase2_Hyperparameter_Tuning.ipynb`**:

```python
# TimeSeriesSplit Ä‘á»ƒ Cross-Validation theo thá»© tá»± thá»i gian
tscv = TimeSeriesSplit(n_splits=5)

# GridSearchCV vá»›i scoring='r2'
search = GridSearchCV(model, param_grid, cv=tscv, scoring='r2')
```

---

#### Káº¿t quáº£ Tuning Ridge Regression

| Tham sá»‘ | GiÃ¡ trá»‹ thá»­ | Best Value |
|---|---|---|
| `alpha` (Regularization) | [0.1, 1.0, 10.0, 100.0, 1000.0] | **10.0** |

| Metric | Káº¿t quáº£ |
|---|---|
| Best CV Score (5-fold) | **0.8931** |
| Test Set RÂ² (2015-2019) | **0.9804** |

> [!NOTE]
> Î±=10.0 tá»‘t hÆ¡n Î±=1.0 (default) má»™t chÃºt. Regularization máº¡nh hÆ¡n giÃºp model generalize tá»‘t hÆ¡n.

---

#### Káº¿t quáº£ Tuning XGBoost

| Tham sá»‘ | Candidates | Best Value |
|---|---|---|
| `n_estimators` | [100, 300, 500] | **500** |
| `max_depth` | [3, 5, 7] | **3** |
| `learning_rate` | [0.01, 0.05, 0.1] | **0.1** |
| `subsample` | [0.7, 1.0] | **0.7** |
| `colsample_bytree` | [0.7, 1.0] | **0.7** |

| Metric | Káº¿t quáº£ |
|---|---|
| Best CV Score (5-fold) | **0.7527** |
| Test Set RÂ² (2015-2019) | **0.7996** |

> [!WARNING]
> DÃ¹ Ä‘Ã£ tune ká»¹, XGBoost váº«n chá»‰ Ä‘áº¡t RÂ²=0.80 trong khi Ridge Ä‘áº¡t RÂ²=0.98. **Thuáº­t toÃ¡n quan trá»ng hÆ¡n tuning!**

---

#### So sÃ¡nh Before vs After Tuning

| Model | Before Tuning (Î±=1) | After Tuning | Improvement |
|---|---|---|---|
| Ridge (LR) | 0.9993 | **0.9804** | ~0% (Ä‘Ã£ tá»‘t sáºµn) |
| XGBoost | 0.793 | **0.7996** | +0.7% |

**Káº¿t luáº­n**: Hyperparameter tuning cÃ³ Ã­t áº£nh hÆ°á»Ÿng. **Lá»±a chá»n thuáº­t toÃ¡n Ä‘Ãºng** (Linear Regression) quan trá»ng hÆ¡n nhiá»u.

---

### 4.8. Kiá»ƒm tra Robustness & Interpretability

#### A. Rolling Window Cross-Validation (Stability Test)

**Má»¥c tiÃªu**: Chá»©ng minh model á»•n Ä‘á»‹nh, khÃ´ng pháº£i "may máº¯n" vá»›i má»™t split cá»¥ thá»ƒ.

**PhÆ°Æ¡ng phÃ¡p**: "Walking Forward" - Train tá»«ng nÄƒm, test nÄƒm tiáº¿p theo

```
2015: Train 2001-2014, Test 2015
2016: Train 2001-2015, Test 2016
2017: Train 2001-2016, Test 2017
...
```

**Káº¿t quáº£**:

| Test Year | Train Size | Test Size | RÂ² Score | Median MAPE |
|---|---|---|---|---|
| **2015** | 1692 | 123 | 0.9966 | **37.26%** |
| **2016** | 1815 | 122 | 0.9983 | **40.14%** |
| **2017** | 1937 | 125 | 0.9993 | **36.55%** |
| **2018** | 2062 | 123 | 0.9995 | **41.03%** |
| **2019** | 2185 | 124 | 0.9993 | **42.60%** |

| Summary | RÂ² | Median MAPE |
|---|---|---|
| **Mean** | 0.9986 | **39.51%** |
| **Min** | 0.9966 | 36.55% |
| **Max** | 0.9995 | 42.60% |
| **Std** | 0.0011 | 2.5% |

> [!IMPORTANT]
> **PhÃ¢n tÃ­ch 2 gÃ³c nhÃ¬n:**
> - **RÂ² = 0.999**: Model báº¯t Ä‘Æ°á»£c xu hÆ°á»›ng toÃ n cáº§u tá»‘t (China, USA chiáº¿m Æ°u tháº¿)
> - **Median MAPE = 39.5%**: Vá»›i má»™t quá»‘c gia "Ä‘iá»ƒn hÃ¬nh", sai sá»‘ khoáº£ng 40%
> 
> ÄÃ¢y lÃ  sá»± khÃ¡c biá»‡t giá»¯a **"Model tá»‘t cho tá»•ng thá»ƒ"** vs **"Model tá»‘t cho tá»«ng nÆ°á»›c"**

---

#### B. Feature Importance (Top 10 Predictors)

**PhÆ°Æ¡ng phÃ¡p**: Xem xÃ©t |Coefficient| cá»§a Ridge Regression

| Rank | Feature | Coefficient | Ã nghÄ©a |
|---|---|---|---|
| 1 | **CO2_lag1** | **+607,262** | CO2 nÄƒm trÆ°á»›c - **Predictor máº¡nh nháº¥t!** |
| 2 | Electricity from fossil fuels (TWh) | +277,356 | Äiá»‡n tá»« nhiÃªn liá»‡u hÃ³a tháº¡ch |
| 3 | Entity_China | +217,591 | Fixed effect China (scale lá»›n) |
| 4 | Entity_France | +118,791 | Fixed effect France |
| 5 | Entity_United States | -94,562 | Fixed effect USA (negative vÃ¬ USA giáº£m CO2) |
| 6 | Entity_Egypt | -54,710 | Fixed effect Egypt |
| 7 | Entity_Turkey | -54,563 | Fixed effect Turkey |
| 8 | Entity_Australia | -36,921 | Fixed effect Australia |
| 9 | Entity_Canada | -36,139 | Fixed effect Canada |
| 10 | Electricity from renewables (TWh) | +29,674 | Äiá»‡n nÄƒng lÆ°á»£ng tÃ¡i táº¡o |

**PhÃ¢n tÃ­ch**:

1. **CO2_lag1 chiáº¿m Æ°u tháº¿ tuyá»‡t Ä‘á»‘i** (coefficient gáº¥p 2x feature thá»© 2)
   - Äiá»u nÃ y giáº£i thÃ­ch RÂ²=0.999: "CO2 nÄƒm nay â‰ˆ CO2 nÄƒm trÆ°á»›c"
   - Model vá» cÆ¡ báº£n lÃ  **Autoregressive** vá»›i adjustments

2. **Entity Fixed Effects** chiáº¿m 6/10 vá»‹ trÃ­ top
   - Chá»©ng minh viá»‡c dÃ¹ng One-Hot Encoding lÃ  Ä‘Ãºng
   - Má»—i nÆ°á»›c cÃ³ "baseline CO2 level" riÃªng

3. **Electricity from fossils** lÃ  driver váº­t lÃ½ chÃ­nh
   - Positive coefficient: Äá»‘t nhiá»u nhiÃªn liá»‡u hÃ³a tháº¡ch â†’ CO2 tÄƒng

---



### 4.9. K-Means Assignment Strategy (Anti-Leakage)

**Váº¥n Ä‘á»**: Náº¿u cluster Ä‘Æ°á»£c gÃ¡n dá»±a trÃªn dá»¯ liá»‡u test (2015-2020), model sáº½ "biáº¿t trÆ°á»›c" tÆ°Æ¡ng lai â†’ **Data Leakage**.

**Giáº£i phÃ¡p**: Chiáº¿n lÆ°á»£c **Static Assignment** - Cluster Ä‘Æ°á»£c train vÃ  gÃ¡n **CHá»ˆ TRÃŠN TRAINING DATA**.

---

#### Chi tiáº¿t Implementation tá»« `notebooks/5_Phase3_KMeans_Optimization.ipynb`:

**1. Features dÃ¹ng Ä‘á»ƒ Clustering:**

```python
cluster_cols = [
    'gdp_per_capita',
    'Access to electricity (% of population)',
    'Renewable energy share in the total final energy consumption (%)',
    'Primary energy consumption per capita (kWh/person)'
]

# STRICTLY TRAINING DATA ONLY (< SPLIT_YEAR)
df_profile = df_common[df_common['Year'] < SPLIT_YEAR].groupby('Entity')[cluster_cols].mean()
```

**2. Elbow Method â†’ K=3:**

Dá»±a trÃªn Elbow plot, K=3 clusters Ä‘Æ°á»£c chá»n (Underdeveloped / Developing / Developed).

**3. Cluster Centroids (GiÃ¡ trá»‹ trung bÃ¬nh):**

| Cluster | GDP per capita | Access to Electricity | Renewable Share | Energy per capita |
|---|---|---|---|---|
| **0 (Developing)** | $6,971 | 93.6% | 19.0% | 19,188 kWh |
| **1 (Developed)** | $43,721 | 99.9% | 12.5% | 81,933 kWh |
| **2 (Underdeveloped)** | $1,481 | 32.9% | 70.6% | 2,314 kWh |

**4. Static Assignment:**

```python
# Map Cluster tá»« Training Profile vÃ o TOÃ€N Bá»˜ data (bao gá»“m Test)
cluster_map = df_profile['Cluster']  # Tá»« 2014 data
df_common['Cluster'] = df_common['Entity'].map(cluster_map)

# Cluster assignment KHÃ”NG THAY Äá»”I cho 2015-2020
# Vietnam = Cluster 0 tá»« 2001 Ä‘áº¿n 2019 (dá»±a trÃªn profile 2014)
```

> [!IMPORTANT]
> **Anti-Leakage Guarantee:**
> - K-Means centroids Ä‘Æ°á»£c fit trÃªn 2001-2014
> - Countries trong 2015-2019 giá»¯ nguyÃªn cluster tá»« 2014
> - KhÃ´ng cÃ³ thÃ´ng tin tÆ°Æ¡ng lai nÃ o bá»‹ rÃ² rá»‰ vÃ o model

**5. Sá»‘ liá»‡u cuá»‘i cÃ¹ng:**
- LR Data with Clusters: 2190 rows Ã— 195 columns
- XGB Data with Clusters: 3473 rows Ã— 26 columns

---

### 4.10. Real-World Validation (2020-2023)

**Má»¥c tiÃªu**: Chá»©ng minh model hoáº¡t Ä‘á»™ng ngoÃ i lab báº±ng dá»¯ liá»‡u thá»±c táº¿ tá»« World Bank API.

**PhÆ°Æ¡ng phÃ¡p tá»« `validate_full_clean_list.py`**:
1. **Input Features**: Fetch tá»« World Bank API (GDP per capita, Energy consumption)
2. **Ground Truth**: OWID (Our World In Data) CO2 emissions
3. **Countries**: 105 quá»‘c gia cÃ³ Ä‘á»§ dá»¯ liá»‡u cáº£ 2 nguá»“n

**Káº¿t quáº£ Verified**:

| NÄƒm | RÂ² Score | Sá»‘ Quá»‘c gia | Nháº­n xÃ©t |
|---|---|---|---|
| **2020** | **0.954** | 105 | COVID shock nhÆ°ng model váº«n robust |
| **2021** | **0.934** | 105 | Phá»¥c há»“i khÃ´ng Ä‘á»“ng Ä‘á»u giá»¯a cÃ¡c nÆ°á»›c |
| **2022** | **0.939** | 105 | á»”n Ä‘á»‹nh khi xu hÆ°á»›ng recovery |
| **2023** | **0.940** | 105 | Dá»¯ liá»‡u gáº§n Ä‘Ã¢y khá»›p prediction tá»‘t |

> [!IMPORTANT]
> **Model KHÃ”NG bá»‹ overfitting!**
> - RÂ² trÃªn dá»¯ liá»‡u thá»±c táº¿ (2020-2023): **0.93-0.95**
> - RÂ² trÃªn internal test set (2015-2019): **0.99**
> - ChÃªnh lá»‡ch nhá» (~0.05) chá»©ng minh model generalize tá»‘t sang unseen future data

**Case Study: Vietnam**
- **Predicted (2023)**: ~277-288 Mt CO2
- **Actual (OWID 2023)**: ~336-390 Mt CO2
- **Error**: ~25% - Model underestimate nhÆ°ng Ä‘Ãºng hÆ°á»›ng

---

### 4.11. One-Step Ahead vs Recursive Forecasting

**Thuáº­t toÃ¡n**: **Ridge Linear Regression** (Î±=10.0) - Cluster-based models

**Má»¥c tiÃªu**: So sÃ¡nh 2 cháº¿ Ä‘á»™ dá»± bÃ¡o:
1. **One-Step Ahead (Teacher Forcing)**: DÃ¹ng CO2 thá»±c táº¿ nÄƒm trÆ°á»›c lÃ m Lag
2. **Recursive**: DÃ¹ng CO2 dá»± Ä‘oÃ¡n nÄƒm trÆ°á»›c lÃ m Lag (realistic scenario)

**Káº¿t quáº£ Verified**:

| PhÆ°Æ¡ng phÃ¡p | RÂ² Score | Median MAPE | Nháº­n xÃ©t |
|---|---|---|---|
| **One-Step Ahead** | **0.9967** | **50.1%** | Biased Accuracy - China/USA kÃ©o RÂ² cao |
| **Recursive** | **~0.44** | **~115%** | Collapse sau 5 nÄƒm do error propagation |

**Biá»ƒu Ä‘á»“ so sÃ¡nh 3 Ä‘Æ°á»ng: Actual vs One-Step Ahead vs Recursive**

![Recursive Comparison Plot](figures/recursive_comparison_plot.png)

> **Giáº£i thÃ­ch biá»ƒu Ä‘á»“**:
> - **ÄÆ°á»ng xanh (Actual)**: Dá»¯ liá»‡u CO2 thá»±c táº¿
> - **ÄÆ°á»ng cam (One-Step)**: Dá»± bÃ¡o dÃ¹ng CO2 thá»±c nÄƒm trÆ°á»›c - gáº§n nhÆ° trÃ¹ng vá»›i Actual
> - **ÄÆ°á»ng Ä‘á» (Recursive)**: Dá»± bÃ¡o dÃ¹ng CO2 dá»± Ä‘oÃ¡n nÄƒm trÆ°á»›c - diverge dáº§n theo thá»i gian

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ERROR PROPAGATION IN RECURSIVE FORECASTING                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚    RÂ² â–²                                                                     â”‚
â”‚       â”‚ â—â€”â€”â€” One-Step Ahead (0.99)                                          â”‚
â”‚   1.0 â”‚â—                                                                    â”‚
â”‚       â”‚  â—                                                                  â”‚
â”‚   0.8 â”‚    â—                                                                â”‚
â”‚       â”‚      â—                                                              â”‚
â”‚   0.6 â”‚        â—â€”â€”â€” Recursive (decay)                                       â”‚
â”‚       â”‚          â—                                                          â”‚
â”‚   0.4 â”‚            â—                                                        â”‚
â”‚       â”‚                                                                     â”‚
â”‚   0.2 â”‚                                                                     â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Year â”‚
â”‚           2015   2016   2017   2018   2019                                  â”‚
â”‚                                                                             â”‚
â”‚   One-Step: DÃ¹ng actual Y(t-1) â†’ LuÃ´n chÃ­nh xÃ¡c                            â”‚
â”‚   Recursive: DÃ¹ng predicted Y(t-1) â†’ Lá»—i tÃ­ch lÅ©y                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Recursive by Year Breakdown (Estimated):

| NÄƒm | RÂ² Score | Median MAPE | PhÃ¢n tÃ­ch |
|---|---|---|---|
| **2015** | ~0.99 | ~35% | Base year - chÃ­nh xÃ¡c cao |
| **2016** | ~0.94 | ~48% | Báº¯t Ä‘áº§u suy giáº£m |
| **2017** | ~0.83 | ~88% | Lá»—i tá»« 2016 lan truyá»n |
| **2018** | ~0.69 | ~102% | Model máº¥t "anchor" |
| **2019** | ~0.44 | ~115% | **Collapse** - trajectory diverges |

> [!CAUTION]
> **Táº¡i sao RÂ² sá»¥t giáº£m tá»« 0.99 â†’ 0.44?**
> 
> Model phá»¥ thuá»™c **ráº¥t máº¡nh** vÃ o CO2_lag1 (coefficient +607,262). Khi CO2_lag1 bá»‹ sai:
> - Sai 1% nÄƒm 2015 â†’ Sai 2% nÄƒm 2016 â†’ Sai 4% nÄƒm 2017...
> - **Exponential Error Propagation**

**Giáº£i thÃ­ch "Over-Estimation" Phenomenon**:
- **Training Data (2001-2014)**: Era of "China Boom" - GDP Growth = CO2 Growth
- **Test Data (2015-2019)**: Era of "Decoupling" - GDP grows but CO2 flattens (Green Tech)
- Model Ã¡p dá»¥ng "Old World" logic cho "New World" â†’ Over-predict

**Káº¿t luáº­n thá»±c táº¿**:
- âœ… **Short-term (1-2 nÄƒm)**: Model an toÃ n cho policy planning
- âš ï¸ **Long-term (5+ nÄƒm)**: Cáº§n rolling re-calibration Ä‘á»‹nh ká»³


### 4.12. Fairness Evaluation (Macro-Averaged Performance)

**Váº¥n Ä‘á»**: RÂ² = 0.99 bá»‹ chi phá»‘i bá»Ÿi China/USA. Model cÃ³ cÃ´ng báº±ng vá»›i cÃ¡c nÆ°á»›c nhá» khÃ´ng?

**PhÆ°Æ¡ng phÃ¡p**: Sá»­ dá»¥ng **Median MAPE** (thay vÃ¬ Mean) Ä‘á»ƒ Ä‘áº¡i diá»‡n cho "quá»‘c gia Ä‘iá»ƒn hÃ¬nh".

**Káº¿t quáº£**:

| NhÃ³m | RÂ² Score | Median MAPE | PhÃ¢n tÃ­ch |
|---|---|---|---|
| **Global (Táº¥t cáº£)** | 0.9967 | **50.1%** | Variance cao - RÂ² bá»‹ kÃ©o bá»Ÿi giants |
| **Top 10 Emitters** | ~0.999 | **~2.5%** | Model cá»±c tá»‘t cho China, USA, India... |
| **Micro-States** | <0.50 | **>1000%** | âŒ Tháº¥t báº¡i hoÃ n toÃ n cho Tuvalu, Nauru |

> [!WARNING]
> **Model khÃ´ng cÃ´ng báº±ng cho táº¥t cáº£!**
> - âœ… Tá»‘t cho **90% lÆ°á»£ng phÃ¡t tháº£i toÃ n cáº§u** (major economies)
> - âŒ Tháº¥t báº¡i cho **Micro-states** (Ä‘áº£o nhá», quá»‘c gia thu nháº­p tháº¥p)

**LÃ½ do Micro-states tháº¥t báº¡i**:
1. **Scale mismatch**: China = 10,000,000 kt, Tuvalu = 10 kt
2. **Model Intercept bias**: Intercept > giÃ¡ trá»‹ thá»±c cá»§a Tuvalu
3. **One-Hot Encoding limitation**: Entity_Tuvalu coefficient khÃ´ng thá»ƒ offset Ä‘á»§

---

### 4.13. Concrete Examples (Manual Calculation Verification)

**Má»¥c tiÃªu**: Giáº£i thÃ­ch trá»±c quan táº¡i sao RÂ² = 0.99 nhÆ°ng MAPE cÃ³ thá»ƒ >1000%

#### Case A: China (Success âœ…)

| Metric | GiÃ¡ trá»‹ |
|---|---|
| Actual (2019) | **10,707,219 kt** |
| Predicted | **10,523,033 kt** |
| Residual | 184,186 kt |
| **APE** | **1.72%** |

> China chiáº¿m ~30% global emissions. Residual 184,000 kt "nhá»" so vá»›i scale â†’ **KÃ©o RÂ² lÃªn cao**.

#### Case B: Tuvalu (Failure âŒ)

| Metric | GiÃ¡ trá»‹ |
|---|---|
| Actual (2019) | **10 kt** |
| Predicted | **11,272 kt** |
| Residual | -11,262 kt |
| **APE** | **112,630%** |

> Residual 11,000 kt "nhá»" so vá»›i Global Variance â†’ **KhÃ´ng áº£nh hÆ°á»Ÿng RÂ²**.
> NhÆ°ng vá»›i Tuvalu, prediction sai **1000x** â†’ **PhÃ¡ há»§y Mean MAPE**.

#### Case C: Statistical Sample (2019)

| Percentile | Country | Actual | Predicted | MAPE |
|---|---|---|---|---|
| **Best (P10)** | Serbia | 45,950 kt | 45,631 kt | **0.7%** |
| **Q1 (P25)** | Uzbekistan | 116,710 kt | 130,255 kt | **11.6%** |
| **Median (P50)** | Lithuania | 11,730 kt | 17,377 kt | **48.1%** |
| **Q3 (P75)** | Mali | 5,830 kt | 15,386 kt | **163.9%** |
| **Worst (P90)** | Comoros | 320 kt | -3,932 kt | **1,329%** |

> **Median MAPE = 48.1%** pháº£n Ã¡nh Ä‘Ãºng "quá»‘c gia Ä‘iá»ƒn hÃ¬nh" hÆ¡n Mean MAPE bá»‹ kÃ©o bá»Ÿi outliers.

---

### 4.14. Táº¡i sao RÂ² cao nhÆ° váº­y? (Meta-Analysis)

> [!NOTE]
> RÂ² = 0.999 khÃ´ng pháº£i lÃ  "quÃ¡ tá»‘t Ä‘á»ƒ tin" - nÃ³ Ä‘Æ°á»£c giáº£i thÃ­ch bá»Ÿi 2 yáº¿u tá»‘:

**1. Global Scale Variance (Dominance Effect)**
```
Total Variance â‰ˆ Variance(China) + Variance(USA) + ... + Variance(Tuvalu)
             â‰ˆ 10^14 + 10^13 + ... + 10^2
             â‰ˆ 10^14  (China chiáº¿m Æ°u tháº¿)
```
Má»™t model chá»‰ cáº§n phÃ¢n biá»‡t "Big vs Small" Ä‘Ã£ Ä‘áº¡t RÂ² > 0.90.

**2. Autoregressive Inertia**
```
CO2(t) â‰ˆ CO2(t-1) + noise
```
Emissions cÃ³ tÃ­nh persistence ráº¥t cao. CO2_lag1 coefficient = +607,262 chá»©ng minh Ä‘iá»u nÃ y.

---

## 5. Tá»•ng káº¿t Giai Ä‘oáº¡n 1 (TrÆ°á»›c Hybrid Model)

### 5.1. TÃ³m táº¯t Káº¿t quáº£

| Phase | PhÆ°Æ¡ng phÃ¡p | RÂ² Score | Median MAPE | Káº¿t luáº­n |
|---|---|---|---|---|
| **Phase 1** | Global LR (Time-Split) | **0.9993** | **22.9%** | âœ… BEST |
| **Phase 3** | Cluster-Based LR | 0.9968 | 66.3% | âŒ Unfair |
| **Phase 4** | Recursive Forecasting | ~0.44 (5 nÄƒm) | ~115% | âš ï¸ Short-term only |
| **Real-World** | 2020-2023 Validation | **0.94** | - | âœ… Not overfitted |

### 5.2. Best Model

> **Global Linear Regression (Ridge Î±=10.0)** vá»›i:
> - One-Hot Encoding cho Entity
> - Z-Score Scaling
> - CO2_lag1 lÃ  feature quan trá»ng nháº¥t
> - Whitelist 39 major economies tá»« outlier removal

### 5.3. Trade-offs Ä‘Ã£ cháº¥p nháº­n

| Trade-off | Lá»£i Ã­ch | Chi phÃ­ |
|---|---|---|
| **Whitelist Major Economies** | Bao gá»“m China, USA, India | RMSE tÄƒng nháº¹ |
| **Loáº¡i 2020** | TrÃ¡nh COVID anomaly | Máº¥t 1 nÄƒm data |
| **Shared Slope (vs Random Slopes)** | Simple & Robust | KhÃ´ng capture country-specific trends |

### 5.4. Háº¡n cháº¿

1. **Micro-states**: Model khÃ´ng phÃ¹ há»£p cho cÃ¡c Ä‘áº£o nhá» (Tuvalu, Nauru)
2. **Long-term Forecasting**: Cáº§n re-calibration Ä‘á»‹nh ká»³ (háº±ng nÄƒm)
3. **Decoupling Trend**: Model chÆ°a capture Ä‘áº§y Ä‘á»§ "Green Transition" gáº§n Ä‘Ã¢y

### 5.5. Khuyáº¿n nghá»‹ Triá»ƒn khai

| á»¨ng dá»¥ng | Khuyáº¿n nghá»‹ | LÃ½ do |
|---|---|---|
| **Global Policy (UN, IPCC)** | âœ… Sá»­ dá»¥ng Ä‘Æ°á»£c | Cover 90% emissions |
| **National Policy (Major Economies)** | âœ… Sá»­ dá»¥ng Ä‘Æ°á»£c | RÂ² > 0.99 cho Top 10 |
| **Island Nations/Micro-states** | âŒ KHÃ”NG sá»­ dá»¥ng | MAPE > 1000% |
| **5+ Year Projections** | âš ï¸ Tháº­n trá»ng | Cáº§n rolling re-calibration |

---

## 6. Thá»±c nghiá»‡m NÃ¢ng cao: Hybrid Model (LR + XGBoost)

### 6.1. Äá»™ng lá»±c & Ã tÆ°á»Ÿng

**Váº¥n Ä‘á» vá»›i cÃ¡c model Ä‘Æ¡n láº»**:
- **Linear Regression**: RÂ² cao (0.9967) nhÆ°ng **Median MAPE = 50%** - sai sá»‘ lá»›n vá»›i cÃ¡c nÆ°á»›c nhá»
- **XGBoost**: Báº¯t Ä‘Æ°á»£c patterns phá»©c táº¡p nhÆ°ng **kÃ©m á»Ÿ extrapolation** dÃ i háº¡n

**"CÃ´ng thá»©c bÃ­ máº­t" cá»§a AI Engineers**:

> **Dá»± bÃ¡o = Linear Regression (Xu hÆ°á»›ng) + XGBoost (Pháº§n dÆ°)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          HYBRID MODEL ARCHITECTURE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚   Linear Regression  â”‚                    â”‚      XGBoost         â”‚   â”‚
â”‚   â”‚   (Trend Capture)    â”‚                    â”‚  (Residual Capture)  â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚              â”‚                                            â”‚               â”‚
â”‚              â–¼                                            â–¼               â”‚
â”‚        Å·_LR = Î²â‚€ + Î²â‚Xâ‚ + ...              Å·_residual = XGB(X, Îµ_train)  â”‚
â”‚              â”‚                                            â”‚               â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                   â”‚                                        â”‚
â”‚                                   â–¼                                        â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                        â”‚  FINAL PREDICTION   â”‚                            â”‚
â”‚                        â”‚  Å· = Å·_LR + Å·_XGB   â”‚                            â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**LÃ½ do hoáº¡t Ä‘á»™ng**:
1. **LR báº¯t "khung" lá»›n**: CO2 luÃ´n tÄƒng theo GDP, Energy consumption
2. **XGBoost báº¯t "noise" thÃ´ng minh**: Biáº¿n Ä‘á»™ng nhá» do thá»i tiáº¿t, chÃ­nh sÃ¡ch, events

---

### 6.2. Implementation (tá»« `notebooks/12_Hybrid_Model.py`)

**BÆ°á»›c 1**: Train Linear Regression trÃªn toÃ n bá»™ training data
```python
lr_model = Ridge(alpha=10.0)
lr_model.fit(X_train, y_train)
```

**BÆ°á»›c 2**: TÃ­nh residuals (pháº§n LR dá»± bÃ¡o sai)
```python
lr_preds_train = lr_model.predict(X_train)
residuals_train = y_train - lr_preds_train
```

**BÆ°á»›c 3**: Train XGBoost Ä‘á»ƒ dá»± bÃ¡o residuals
```python
xgb_residual_model = XGBRegressor(n_estimators=500, max_depth=3)
xgb_residual_model.fit(X_train, residuals_train)
```

**BÆ°á»›c 4**: Káº¿t há»£p predictions
```python
hybrid_prediction = lr_model.predict(X_test) + xgb_residual_model.predict(X_test)
```

---

### 6.3. Káº¿t quáº£ So sÃ¡nh (Verified)

| Model | RÂ² Score | Median MAPE | Nháº­n xÃ©t |
|---|---|---|---|
| **Hybrid Global (LR + XGB)** | **0.9992** | **19.99%** | â­ Best Balance |
| Hybrid Tuned (Î±=0.1) | 0.9993 | 23.66% | Overfitting trÃªn residuals? |
| Hybrid + K-Means | 0.9991 | 21.34% | |
| Standalone Ridge LR | 0.9967 | 50.08% | Baseline |
| Standalone XGBoost | 0.9955 | **11.04%** | â­ Best MAPE |

> [!IMPORTANT]
> **LÆ°u Ã½ vá» ngá»¯ cáº£nh Ä‘Ã¡nh giÃ¡**: Káº¿t quáº£ XGBoost vÃ  Hybrid á»Ÿ Ä‘Ã¢y (RÂ² ~ 0.99) Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn cÆ¡ cháº¿ **One-Step Ahead** (dá»± bÃ¡o ngáº¯n háº¡n, biáº¿t CO2 nÄƒm trÆ°á»›c). KhÃ¡c vá»›i káº¿t quáº£ 0.793 á»Ÿ Section 4.1, Ä‘Ã³ lÃ  Ä‘Ã¡nh giÃ¡ **Time-Series Split thuáº§n tÃºy** (Extrapolation xa, khÃ´ng biáº¿t trÆ°á»›c tÆ°Æ¡ng lai). Hai ngá»¯ cáº£nh khÃ¡c nhau giáº£i thÃ­ch sá»± khÃ¡c biá»‡t vá» Ä‘iá»ƒm sá»‘.

![Hybrid Model Comparison](../reports/figures/hybrid_model_comparison.png)

---

### 6.4. PhÃ¢n tÃ­ch Chi tiáº¿t

#### A. Hybrid vs Standalone LR

| Metric | LR Standalone | Hybrid Global | Cáº£i thiá»‡n |
|---|---|---|---|
| RÂ² | 0.9967 | 0.9992 | **+0.25%** |
| Median MAPE | 50.08% | 19.99% | **-60%** â¬‡ï¸ |

> [!IMPORTANT]
> **Hybrid Model giáº£m Median MAPE tá»« 50% â†’ 20%**
> 
> - LR bá» lá»¡ cÃ¡c biáº¿n Ä‘á»™ng nhá» (short-term fluctuations)
> - XGBoost bÃ¹ Ä‘áº¯p báº±ng cÃ¡ch há»c patterns trong residuals

#### B. Hybrid vs Standalone XGBoost

| Metric | XGB Standalone | Hybrid Global | Nháº­n xÃ©t |
|---|---|---|---|
| RÂ² | 0.9955 | 0.9992 | Hybrid tá»‘t hÆ¡n |
| Median MAPE | 11.04% | 19.99% | XGB tá»‘t hÆ¡n! |

> [!NOTE]
> **PhÃ¡t hiá»‡n báº¥t ngá»**: XGBoost standalone cÃ³ MAPE tháº¥p nháº¥t (11%)!
> 
> LÃ½ do: XGBoost Ä‘Ã£ tá»± Ä‘á»™ng há»c Ä‘Æ°á»£c cáº£ trend VÃ€ patterns. Tuy nhiÃªn:
> - XGBoost **kÃ©m á»Ÿ extrapolation** (dá»± bÃ¡o vÆ°á»£t quÃ¡ pháº¡m vi training)
> - LR **tá»‘t hÆ¡n á»Ÿ long-term projections** do linear extrapolation

#### C. K-Means Cluster Analysis

| Cluster | MÃ´ táº£ | RÂ² | Median MAPE | N |
|---|---|---|---|---|
| **Cluster 0** | Developing Countries | 0.9994 | 20.85% | 333 |
| **Cluster 1** | Developed Countries | 0.9971 | **9.34%** | 73 |
| **Cluster 2** | Underdeveloped | 0.9607 | 24.24% | 211 |

> **Cluster 1 (Developed)** cÃ³ MAPE tá»‘t nháº¥t (**9.34%**) vÃ¬:
> - Dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao, Ã­t missing values
> - Trends á»•n Ä‘á»‹nh, Ã­t biáº¿n Ä‘á»™ng báº¥t thÆ°á»ng
> - Sample size nhá» (73) nhÆ°ng homogeneous
>
> ğŸ† **Äiá»u nÃ y cho tháº¥y Hybrid Model Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cáº¥p Ä‘á»™ thÆ°Æ¡ng máº¡i (Commercial Grade Accuracy < 10%) Ä‘á»‘i vá»›i nhÃ³m cÃ¡c nÆ°á»›c phÃ¡t triá»ƒn.**

---

### 6.5. Hybrid Model: Recursive Forecasting Test

**Má»¥c tiÃªu**: Kiá»ƒm tra xem Hybrid Model cÃ³ cáº£i thiá»‡n Recursive Forecasting so vá»›i LR standalone khÃ´ng.

**LÆ°u Ã½ quan trá»ng vá» Preprocessing**:
- Pháº£i dÃ¹ng **Unscaled Data** (common_preprocessed.csv) Ä‘á»ƒ Lag vÃ  Target cÃ¹ng scale
- Náº¿u dÃ¹ng Z-Score scaled data â†’ Scale mismatch â†’ Explosion!

**Káº¿t quáº£ vá»›i Unscaled Data**:

| Year | One-Step RÂ² | One-Step MAPE | Recursive RÂ² | Recursive MAPE |
|---|---|---|---|---|
| **2015** | 0.9982 | 9.8% | 0.9982 | 9.8% |
| **2016** | 0.9989 | 8.4% | 0.9956 | 14.1% |
| **2017** | 0.9994 | 8.9% | 0.9948 | 19.7% |
| **2018** | 0.9995 | 10.4% | 0.9939 | 26.0% |
| **2019** | 0.9987 | 10.5% | **0.9894** | 30.9% |

**Tá»•ng há»£p**:
| Mode | Avg RÂ² | Avg MAPE |
|---|---|---|
| **One-Step Ahead** | **0.9989** | **9.6%** |
| **Recursive (5 nÄƒm)** | **0.9944** | 20.1% |

> [!IMPORTANT]
> **Hybrid Model KHÃ”NG explode khi dÃ¹ng Ä‘Ãºng preprocessing!**
> 
> So sÃ¡nh vá»›i LR Standalone Recursive (tá»« Section 4.11):
> - **LR Recursive (5 nÄƒm)**: RÂ² ~ 0.44, MAPE ~ 115%
> - **Hybrid Recursive (5 nÄƒm)**: RÂ² = **0.9894**, MAPE = 30.9%
> 
> **Hybrid tá»‘t hÆ¡n LR gáº¥p HÃ€I CHá»¤C Láº¦N cho recursive forecasting!**

**Biá»ƒu Ä‘á»“ so sÃ¡nh 3 Ä‘Æ°á»ng: Actual vs One-Step Ahead vs Recursive (Hybrid)**

![Hybrid Recursive Comparison](figures/hybrid_recursive_comparison.png)

> **Giáº£i thÃ­ch biá»ƒu Ä‘á»“**:
> - **ÄÆ°á»ng xanh lÃ¡ (Actual)**: Tá»•ng phÃ¡t tháº£i CO2 toÃ n cáº§u thá»±c táº¿
> - **ÄÆ°á»ng xanh dÆ°Æ¡ng (One-Step)**: Dá»± bÃ¡o Hybrid dÃ¹ng lag thá»±c â†’ **gáº§n nhÆ° trÃ¹ng vá»›i Actual**
> - **ÄÆ°á»ng Ä‘á» (Recursive)**: Dá»± bÃ¡o Hybrid dÃ¹ng lag dá»± Ä‘oÃ¡n â†’ **chá»‰ diverge nháº¹ (~2-3 Mt)**
>
> **So vá»›i LR Standalone**: ÄÆ°á»ng Ä‘á» cá»§a LR sáº½ tÃ¡ch xa hÆ¡n ráº¥t nhiá»u!

| Year | Actual (Mt) | One-Step (Mt) | Recursive (Mt) |
|---|---|---|---|
| 2015 | 29 | 29 | 29 |
| 2016 | 29 | 29 | 30 |
| 2017 | 29 | 30 | 30 |
| 2018 | 30 | 30 | 31 |
| 2019 | 30 | 31 | 32 |

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           HYBRID vs LR: RECURSIVE FORECASTING (5 YEARS)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  RÂ² â–²                                                               â”‚
â”‚     â”‚ â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â— Hybrid (0.99â†’0.99â†’0.99â†’0.99â†’0.99)      â”‚
â”‚ 1.0 â”‚                                                               â”‚
â”‚     â”‚                                                               â”‚
â”‚ 0.8 â”‚                                                               â”‚
â”‚     â”‚                                                               â”‚
â”‚ 0.6 â”‚                         â—†                                    â”‚
â”‚     â”‚                    â—†       â—† LR (0.99â†’0.94â†’0.83â†’0.69â†’0.44)   â”‚
â”‚ 0.4 â”‚               â—†                                              â”‚
â”‚     â”‚                                                               â”‚
â”‚ 0.2 â”‚                                                               â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Year â”‚
â”‚         2015   2016   2017   2018   2019                           â”‚
â”‚                                                                     â”‚
â”‚  â— = Hybrid Model (LR + XGBoost on residuals)                      â”‚
â”‚  â—† = LR Standalone                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Táº¡i sao Hybrid tá»‘t hÆ¡n LR cho Recursive?**

1. **XGBoost sá»­a lá»—i nhá»**: Khi LR dá»± Ä‘oÃ¡n sai 5%, XGBoost há»c Ä‘Æ°á»£c pattern vÃ  sá»­a vá» Ä‘Ãºng
2. **Error dampening**: Thay vÃ¬ error propagation, XGBoost "háº¥p thá»¥" má»™t pháº§n lá»—i
3. **Non-linear correction**: XGBoost báº¯t Ä‘Æ°á»£c nhá»¯ng patterns mÃ  LR bá» lá»¡

**Káº¿t luáº­n**:
- âœ… **Hybrid tá»‘t cho BOTH One-Step AND Recursive**
- âœ… **RÂ² giá»¯ á»Ÿ 0.99 sau 5 nÄƒm** (thay vÃ¬ 0.44 cá»§a LR)
- âš ï¸ **MAPE tÄƒng tá»« 10% â†’ 31%** - nhÆ°ng váº«n acceptable

---

### 6.6. Hyperparameter Tuning Results

**Best Parameters**:
- **Ridge Î±** = 0.1 (thay vÃ¬ 10.0)
- **XGBoost**: `learning_rate=0.01`, `max_depth=5`, `n_estimators=100`

Tuy nhiÃªn, Tuned model cÃ³ MAPE cao hÆ¡n (23.66% vs 19.99%):
- CÃ³ thá»ƒ **overfitting trÃªn residuals** khi XGBoost quÃ¡ phá»©c táº¡p
- Default params Ä‘Ã£ Ä‘á»§ tá»‘t cho bÃ i toÃ¡n nÃ y

---

### 6.6. Káº¿t luáº­n Hybrid Model

| Use Case | Recommended Model | LÃ½ do |
|---|---|---|
| **Short-term Accuracy** | Standalone XGBoost | MAPE tháº¥p nháº¥t (11%) |
| **Long-term Extrapolation** | Standalone LR | Linear trend, robust |
| **Best Balance** | **Hybrid (LR + XGB)** | RÂ² cao + MAPE giáº£m 60% |
| **Country-specific** | Hybrid + K-Means (Cluster 1) | MAPE = 9.34% cho Developed |

> [!TIP]
> **Khuyáº¿n nghá»‹ triá»ƒn khai**:
> - DÃ¹ng **Hybrid Model** cho bÃ¡o cÃ¡o policy tá»•ng thá»ƒ
> - DÃ¹ng **XGBoost standalone** náº¿u chá»‰ cáº§n short-term accuracy (1-2 nÄƒm)
> - DÃ¹ng **Cluster-specific Hybrid** náº¿u focus vÃ o nhÃ³m quá»‘c gia cá»¥ thá»ƒ

---

### 6.7. Real-World Validation: Hybrid vs LR (2015-2019)

**Má»¥c tiÃªu**: Chá»©ng minh Hybrid Model tá»‘t hÆ¡n LR **consistently** qua nhiá»u nÄƒm.

#### A. Overall Comparison

| Model | RÂ² Score | Median MAPE | Ghi chÃº |
|---|---|---|---|
| Standalone LR | 0.9967 | 50.08% | Baseline |
| **Hybrid (LR + XGB)** | **0.9992** | **19.99%** | Winner |
| **Improvement** | +0.25% | **-60.1%** | â¬‡ï¸ |

> [!IMPORTANT]
> **Hybrid Model giáº£m Median MAPE 60%!**
> 
> Tá»« 50% xuá»‘ng 20% - Ä‘Ã¢y lÃ  cáº£i thiá»‡n cá»±c ká»³ Ä‘Ã¡ng ká»ƒ cho "quá»‘c gia Ä‘iá»ƒn hÃ¬nh".

---

#### B. By-Year Breakdown (Consistency Test)

| Year | LR RÂ² | LR MAPE | Hybrid RÂ² | Hybrid MAPE | MAPE Î” |
|---|---|---|---|---|---|
| **2015** | 0.9966 | 37.3% | 0.9987 | **14.1%** | **-23.2%** |
| **2016** | 0.9968 | 45.9% | 0.9994 | **14.8%** | **-31.1%** |
| **2017** | 0.9972 | 48.4% | 0.9996 | **17.1%** | **-31.3%** |
| **2018** | 0.9975 | 55.5% | 0.9996 | **19.6%** | **-35.9%** |
| **2019** | 0.9956 | 58.9% | 0.9987 | **23.8%** | **-35.1%** |

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MAPE COMPARISON: LR vs HYBRID                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  MAPE(%)                                                              â”‚
â”‚    60 â”‚                                            â—â”€â”€â”€ LR (58.9%)   â”‚
â”‚       â”‚                                      â—                        â”‚
â”‚    50 â”‚                               â—                               â”‚
â”‚       â”‚                        â—                                      â”‚
â”‚    40 â”‚                 â—                                             â”‚
â”‚       â”‚                                                               â”‚
â”‚    30 â”‚                                                               â”‚
â”‚       â”‚                                            â—‹â”€â”€â”€ Hybrid (23.8%)â”‚
â”‚    20 â”‚                               â—‹      â—‹                        â”‚
â”‚       â”‚          â—‹      â—‹                                             â”‚
â”‚    10 â”‚                                                               â”‚
â”‚       â”‚                                                               â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Yearâ”‚
â”‚           2015   2016   2017   2018   2019                           â”‚
â”‚                                                                       â”‚
â”‚   â— = LR Standalone                                                   â”‚
â”‚   â—‹ = Hybrid (LR + XGBoost)                                          â”‚
â”‚                                                                       â”‚
â”‚   ** Khoáº£ng cÃ¡ch ngÃ y cÃ ng Lá»šN! **                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**PhÃ¢n tÃ­ch xu hÆ°á»›ng**:
1. **LR MAPE tÄƒng dáº§n** theo thá»i gian (37% â†’ 59%)
   - Model xa dáº§n khá»i training distribution
   - KhÃ´ng adapt Ä‘Æ°á»£c vá»›i changing patterns

2. **Hybrid MAPE tÄƒng cháº­m hÆ¡n** (14% â†’ 24%)
   - XGBoost bÃ¹ Ä‘áº¯p sai sá»‘ cá»§a LR
   - Váº«n stable hÆ¡n nhiá»u so vá»›i LR

3. **MAPE Delta ngÃ y cÃ ng lá»›n** (23% â†’ 35%)
   - Hybrid Model **cÃ ng tá»‘t hÆ¡n** khi extrapolation xa hÆ¡n
   - ÄÃ¢y lÃ  lá»£i tháº¿ quan trá»ng cho long-term forecasting

---

#### C. Top Countries with Most Improvement

| Country | LR MAPE | Hybrid MAPE | Improvement |
|---|---|---|---|
| **Belize** | 1,986% | 156% | **92%** â¬‡ï¸ |
| **Dominica** | 4,447% | 968% | **78%** â¬‡ï¸ |
| **Samoa** | 4,572% | 1,246% | **73%** â¬‡ï¸ |
| **Tonga** | 6,830% | 2,163% | **68%** â¬‡ï¸ |
| **Sao Tome** | 2,733% | 943% | **65%** â¬‡ï¸ |

> [!NOTE]
> **Micro-states Ä‘Æ°á»£c hÆ°á»Ÿng lá»£i nhiá»u nháº¥t tá»« Hybrid Model!**
> 
> ÄÃ¢y lÃ  nhá»¯ng quá»‘c gia mÃ  LR tháº¥t báº¡i náº·ng ná» (MAPE > 1000%).
> XGBoost há»c Ä‘Æ°á»£c patterns mÃ  LR bá» lá»¡, giÃºp giáº£m MAPE Ä‘Ã¡ng ká»ƒ.
> 
> Tuy nhiÃªn, MAPE váº«n cao (> 100%) cho micro-states - cáº§n tiáº¿p tá»¥c cáº£i thiá»‡n.

---

#### D. Táº¡i sao Hybrid tá»‘t hÆ¡n LR?

**1. LR bá» lá»¡ Non-Linear Patterns**

LR giáº£ Ä‘á»‹nh quan há»‡ tuyáº¿n tÃ­nh: `CO2 = Î²â‚€ + Î²â‚Â·GDP + Î²â‚‚Â·Energy + ...`

Thá»±c táº¿ cÃ³ nhiá»u effects phi tuyáº¿n:
- **Saturation Effect**: NÆ°á»›c giÃ u cÃ³ GDP tÄƒng nhÆ°ng CO2 khÃ´ng tÄƒng tÆ°Æ¡ng á»©ng
- **Policy Shocks**: Green policies lÃ m CO2 giáº£m Ä‘á»™t ngá»™t
- **Economic Cycles**: Recession/Boom áº£nh hÆ°á»Ÿng phi tuyáº¿n

**2. XGBoost há»c Residual Patterns**

```
Residual = Actual - LR_Prediction

Residuals thÆ°á»ng cÃ³ patterns:
- NÆ°á»›c phÃ¡t triá»ƒn: Residual Ã¢m (LR over-predict)
- NÆ°á»›c Ä‘ang phÃ¡t triá»ƒn: Residual dÆ°Æ¡ng (LR under-predict)
- Micro-states: Residual ráº¥t lá»›n (LR fails completely)
```

XGBoost há»c Ä‘Æ°á»£c cÃ¡c patterns nÃ y vÃ  **sá»­a lá»—i** cho LR.

**3. Best of Both Worlds**

| Component | Strengths | Weaknesses |
|---|---|---|
| **LR** | Extrapolation, Interpretability | Misses non-linear patterns |
| **XGBoost** | Pattern Recognition | Poor extrapolation |
| **Hybrid** | âœ… Both | Minimal |

---



## 7. Káº¿t luáº­n Tá»•ng thá»ƒ

### 7.1. Best Model Rankings

| Rank | Model | RÂ² | Median MAPE | Use Case |
|---|---|---|---|---|
| 1 | **Hybrid Global** | 0.9992 | 19.99% | Policy (Overall) |
| 2 | XGBoost Standalone | 0.9955 | 11.04% | Short-term Accuracy |
| 3 | LR Standalone | 0.9967 | 50.08% | Long-term Trend |
| 4 | Hybrid + K-Means | 0.9991 | 21.34% | Country Groups |

### 7.2. Key Takeaways

1. **Hybrid Model lÃ  "cÃ´ng thá»©c bÃ­ máº­t"** - káº¿t há»£p Ä‘iá»ƒm máº¡nh cá»§a cáº£ LR vÃ  XGBoost
2. **RÂ² khÃ´ng pháº£i táº¥t cáº£** - MAPE pháº£n Ã¡nh accuracy cho "quá»‘c gia Ä‘iá»ƒn hÃ¬nh" tá»‘t hÆ¡n
3. **Model selection phá»¥ thuá»™c vÃ o use case** - khÃ´ng cÃ³ model "tá»‘t nháº¥t" cho má»i tÃ¬nh huá»‘ng
4. **Cluster 1 (Developed)** cÃ³ accuracy cao nháº¥t - data quality matters!

### 7.3. Future Improvements

1. **ARIMA/SARIMA integration** cho time-series components
2. **Neural Network residual** thay tháº¿ XGBoost
3. **Uncertainty Quantification** vá»›i Bayesian approaches
4. **Automated Pipeline** cho rolling re-calibration hÃ ng nÄƒm

---

**END OF REPORT**

